2020-12-11 20:13:42.757587 (MainThread): Running with dbt=0.18.1
2020-12-11 20:13:43.007717 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 20:13:43.008954 (MainThread): Tracking: tracking
2020-12-11 20:13:43.018946 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe6b760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe7a760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe7a700>]}
2020-12-11 20:13:43.049403 (MainThread): Partial parsing not enabled
2020-12-11 20:13:43.051329 (MainThread): Parsing macros/etc.sql
2020-12-11 20:13:43.056387 (MainThread): Parsing macros/catalog.sql
2020-12-11 20:13:43.067067 (MainThread): Parsing macros/adapters.sql
2020-12-11 20:13:43.100624 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 20:13:43.106880 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 20:13:43.112331 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 20:13:43.126054 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 20:13:43.132546 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 20:13:43.148416 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 20:13:43.153265 (MainThread): Parsing macros/core.sql
2020-12-11 20:13:43.157306 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 20:13:43.166820 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 20:13:43.169904 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 20:13:43.189622 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 20:13:43.220318 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 20:13:43.242011 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 20:13:43.244629 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 20:13:43.250961 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 20:13:43.265215 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 20:13:43.272975 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 20:13:43.279895 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 20:13:43.286069 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 20:13:43.287502 (MainThread): Parsing macros/etc/query.sql
2020-12-11 20:13:43.288754 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 20:13:43.290525 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 20:13:43.301348 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 20:13:43.304429 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 20:13:43.306504 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 20:13:43.347490 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 20:13:43.350429 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 20:13:43.352969 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 20:13:43.355034 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 20:13:43.363186 (MainThread): Partial parsing not enabled
2020-12-11 20:13:43.434251 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 20:13:43.456249 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 20:13:43.700752 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 20:13:43.701688 (MainThread): 
2020-12-11 20:13:43.702172 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 20:13:43.704965 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 20:13:43.705178 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 20:13:43.937847 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_dbt-demos_dbt-user".
2020-12-11 20:13:43.938113 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_dbt-demos_dbt-user".
2020-12-11 20:13:43.938205 (ThreadPoolExecutor-0_0): Creating schema "dbt-demos.dbt-user".
2020-12-11 20:13:43.938279 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-12-11 20:13:43.938799 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 20:13:44.145325 (ThreadPoolExecutor-0_0): Retry attempt 1 of 1 after error: BadRequest('POST https://bigquery.googleapis.com/bigquery/v2/projects/dbt-demos/datasets: Invalid dataset ID "dbt-user". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.')
2020-12-11 20:13:45.221396 (MainThread): Connection 'master' was properly closed.
2020-12-11 20:13:45.221537 (MainThread): Connection 'create_dbt-demos_dbt-user' was properly closed.
2020-12-11 20:13:45.221682 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fffbeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110133f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110069700>]}
2020-12-11 20:13:45.221861 (MainThread): Flushing usage events
2020-12-11 20:13:45.532750 (MainThread): Encountered an error:
2020-12-11 20:13:45.532959 (MainThread): Database Error
  Invalid dataset ID "dbt-user". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.
2020-12-11 20:13:45.545203 (MainThread): Traceback (most recent call last):
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 420, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 462, in create_dataset
    api_response = self._call_api(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/dbt-demos/datasets: Invalid dataset ID "dbt-user". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 303, in create_schema
    self.connections.create_dataset(database, schema)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 421, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Invalid dataset ID "dbt-user". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.

2020-12-11 20:15:56.790631 (MainThread): Running with dbt=0.18.1
2020-12-11 20:15:57.061899 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 20:15:57.063118 (MainThread): Tracking: tracking
2020-12-11 20:15:57.072079 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4756a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f484730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4846d0>]}
2020-12-11 20:15:57.099240 (MainThread): Partial parsing not enabled
2020-12-11 20:15:57.100673 (MainThread): Parsing macros/etc.sql
2020-12-11 20:15:57.105288 (MainThread): Parsing macros/catalog.sql
2020-12-11 20:15:57.113633 (MainThread): Parsing macros/adapters.sql
2020-12-11 20:15:57.134752 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 20:15:57.137820 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 20:15:57.141751 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 20:15:57.153674 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 20:15:57.158621 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 20:15:57.173348 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 20:15:57.177662 (MainThread): Parsing macros/core.sql
2020-12-11 20:15:57.182487 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 20:15:57.194666 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 20:15:57.196851 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 20:15:57.217822 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 20:15:57.250502 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 20:15:57.276198 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 20:15:57.278748 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 20:15:57.286489 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 20:15:57.303387 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 20:15:57.311854 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 20:15:57.318872 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 20:15:57.324670 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 20:15:57.325894 (MainThread): Parsing macros/etc/query.sql
2020-12-11 20:15:57.327056 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 20:15:57.329168 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 20:15:57.339116 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 20:15:57.341591 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 20:15:57.343534 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 20:15:57.385920 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 20:15:57.387980 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 20:15:57.390590 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 20:15:57.392861 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 20:15:57.401339 (MainThread): Partial parsing not enabled
2020-12-11 20:15:57.473385 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 20:15:57.497443 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 20:15:57.734503 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 20:15:57.735252 (MainThread): 
2020-12-11 20:15:57.735556 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 20:15:57.738607 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 20:15:57.739066 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 20:15:57.954013 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_dbt-demos_dbt_blake".
2020-12-11 20:15:57.954409 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_dbt-demos_dbt_blake".
2020-12-11 20:15:57.954551 (ThreadPoolExecutor-0_0): Creating schema "dbt-demos.dbt_blake".
2020-12-11 20:15:57.954661 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-12-11 20:15:57.955510 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 20:15:58.563522 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 20:15:58.563789 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 20:15:58.564532 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 20:15:58.833910 (MainThread): 14:15:58 | Concurrency: 1 threads (target='dev')
2020-12-11 20:15:58.834080 (MainThread): 14:15:58 | 
2020-12-11 20:15:58.842579 (Thread-1): Began running node model.jaffle_shop.my_first_dbt_model
2020-12-11 20:15:58.843725 (Thread-1): 14:15:58 | 1 of 2 START table model dbt_blake.my_first_dbt_model................ [RUN]
2020-12-11 20:15:58.844141 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 20:15:58.844295 (Thread-1): Compiling model.jaffle_shop.my_first_dbt_model
2020-12-11 20:15:58.863888 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 20:15:58.865054 (Thread-1): finished collecting timing info
2020-12-11 20:15:58.909093 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 20:15:58.909924 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 20:15:58.910452 (Thread-1): On model.jaffle_shop.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_first_dbt_model"} */


  create or replace table `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2020-12-11 20:16:01.489112 (Thread-1): finished collecting timing info
2020-12-11 20:16:01.489739 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88b1cb82-873a-4d12-828f-e57caaaadcd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6f9070>]}
2020-12-11 20:16:01.490916 (Thread-1): 14:16:01 | 1 of 2 OK created table model dbt_blake.my_first_dbt_model........... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.65s]
2020-12-11 20:16:01.491053 (Thread-1): Finished running node model.jaffle_shop.my_first_dbt_model
2020-12-11 20:16:01.491537 (Thread-1): Began running node model.jaffle_shop.my_second_dbt_model
2020-12-11 20:16:01.492481 (Thread-1): 14:16:01 | 2 of 2 START view model dbt_blake.my_second_dbt_model................ [RUN]
2020-12-11 20:16:01.492744 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 20:16:01.492842 (Thread-1): Compiling model.jaffle_shop.my_second_dbt_model
2020-12-11 20:16:01.497930 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.162', 65203), raddr=('172.217.14.170', 443)>
2020-12-11 20:16:01.498190 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.162', 65204), raddr=('172.217.9.170', 443)>
2020-12-11 20:16:01.498402 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.162', 65206), raddr=('172.217.9.170', 443)>
2020-12-11 20:16:01.498571 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.162', 65205), raddr=('172.217.14.170', 443)>
2020-12-11 20:16:01.498726 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.162', 65208), raddr=('172.217.9.170', 443)>
2020-12-11 20:16:01.498909 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.162', 65207), raddr=('172.217.14.170', 443)>
2020-12-11 20:16:01.499097 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.162', 65210), raddr=('172.217.9.170', 443)>
2020-12-11 20:16:01.499236 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.162', 65209), raddr=('172.217.14.170', 443)>
2020-12-11 20:16:01.503174 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 20:16:01.503614 (Thread-1): finished collecting timing info
2020-12-11 20:16:01.523083 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 20:16:01.523762 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 20:16:01.524263 (Thread-1): On model.jaffle_shop.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_second_dbt_model"} */


  create or replace view `dbt-demos`.`dbt_blake`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
where id = 1;


2020-12-11 20:16:02.534519 (Thread-1): finished collecting timing info
2020-12-11 20:16:02.535178 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88b1cb82-873a-4d12-828f-e57caaaadcd9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f671880>]}
2020-12-11 20:16:02.536415 (Thread-1): 14:16:02 | 2 of 2 OK created view model dbt_blake.my_second_dbt_model........... [CREATE VIEW in 1.04s]
2020-12-11 20:16:02.536561 (Thread-1): Finished running node model.jaffle_shop.my_second_dbt_model
2020-12-11 20:16:02.537432 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 20:16:02.537684 (MainThread): 14:16:02 | 
2020-12-11 20:16:02.537780 (MainThread): 14:16:02 | Finished running 1 table model, 1 view model in 4.80s.
2020-12-11 20:16:02.537855 (MainThread): Connection 'master' was properly closed.
2020-12-11 20:16:02.537910 (MainThread): Connection 'model.jaffle_shop.my_second_dbt_model' was properly closed.
2020-12-11 20:16:02.543881 (MainThread): 
2020-12-11 20:16:02.544091 (MainThread): Completed successfully
2020-12-11 20:16:02.544233 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-12-11 20:16:02.544433 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f70c1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f689c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f689910>]}
2020-12-11 20:16:02.544625 (MainThread): Flushing usage events
2020-12-11 22:29:10.577318 (MainThread): Running with dbt=0.18.1
2020-12-11 22:29:10.848889 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:29:10.850109 (MainThread): Tracking: tracking
2020-12-11 22:29:10.859098 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e1cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e2a640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e2a5e0>]}
2020-12-11 22:29:10.886290 (MainThread): Partial parsing not enabled
2020-12-11 22:29:10.887722 (MainThread): Parsing macros/etc.sql
2020-12-11 22:29:10.892526 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:29:10.899485 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:29:10.923362 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:29:10.927004 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:29:10.930472 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:29:10.940610 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:29:10.946011 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:29:10.961314 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:29:10.965406 (MainThread): Parsing macros/core.sql
2020-12-11 22:29:10.969866 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:29:10.979298 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:29:10.981640 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:29:10.999847 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:29:11.029937 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:29:11.051655 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:29:11.054095 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:29:11.061922 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:29:11.075905 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:29:11.083766 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:29:11.090993 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:29:11.096994 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:29:11.098310 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:29:11.099623 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:29:11.101474 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:29:11.110963 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:29:11.113569 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:29:11.115861 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:29:11.160070 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:29:11.162515 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:29:11.164210 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:29:11.166112 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:29:11.174097 (MainThread): Partial parsing not enabled
2020-12-11 22:29:11.246535 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:29:11.268866 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 22:29:11.281896 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 22:29:11.535432 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:29:11.536241 (MainThread): 
2020-12-11 22:29:11.536646 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:29:11.540261 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:29:11.540598 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:29:11.907468 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:29:11.907738 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:29:11.908323 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:29:12.181422 (MainThread): 16:29:12 | Concurrency: 1 threads (target='dev')
2020-12-11 22:29:12.181717 (MainThread): 16:29:12 | 
2020-12-11 22:29:12.188404 (Thread-1): Began running node model.jaffle_shop.my_first_dbt_model
2020-12-11 22:29:12.190832 (Thread-1): 16:29:12 | 1 of 3 START table model dbt_blake.my_first_dbt_model................ [RUN]
2020-12-11 22:29:12.191348 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 22:29:12.191567 (Thread-1): Compiling model.jaffle_shop.my_first_dbt_model
2020-12-11 22:29:12.214334 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 22:29:12.214870 (Thread-1): finished collecting timing info
2020-12-11 22:29:12.237783 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:29:12.238326 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:29:12.580629 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 22:29:12.581247 (Thread-1): On model.jaffle_shop.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_first_dbt_model"} */


  create or replace table `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2020-12-11 22:29:14.626453 (Thread-1): finished collecting timing info
2020-12-11 22:29:14.627393 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc507005-dbdd-4bd9-a332-e03d61410d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112000430>]}
2020-12-11 22:29:14.629250 (Thread-1): 16:29:14 | 1 of 3 OK created table model dbt_blake.my_first_dbt_model........... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.44s]
2020-12-11 22:29:14.629589 (Thread-1): Finished running node model.jaffle_shop.my_first_dbt_model
2020-12-11 22:29:14.629890 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:29:14.631759 (Thread-1): 16:29:14 | 2 of 3 START view model dbt_blake.customers.......................... [RUN]
2020-12-11 22:29:14.632134 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:29:14.632338 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:29:14.636342 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50443), raddr=('172.217.9.170', 443)>
2020-12-11 22:29:14.636561 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50444), raddr=('172.217.9.170', 443)>
2020-12-11 22:29:14.636779 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50445), raddr=('172.217.9.170', 443)>
2020-12-11 22:29:14.636969 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50446), raddr=('172.217.9.170', 443)>
2020-12-11 22:29:14.637132 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50448), raddr=('172.217.9.170', 443)>
2020-12-11 22:29:14.637314 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50447), raddr=('172.217.9.170', 443)>
2020-12-11 22:29:14.639765 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:29:14.640242 (Thread-1): finished collecting timing info
2020-12-11 22:29:14.662882 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.customers"
2020-12-11 22:29:14.663638 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:29:14.664067 (Thread-1): On model.jaffle_shop.customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.customers"} */


  create or replace view `dbt-demos`.`dbt_blake`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2020-12-11 22:29:15.531974 (Thread-1): finished collecting timing info
2020-12-11 22:29:15.532818 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc507005-dbdd-4bd9-a332-e03d61410d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120aed90>]}
2020-12-11 22:29:15.534246 (Thread-1): 16:29:15 | 2 of 3 OK created view model dbt_blake.customers..................... [CREATE VIEW in 0.90s]
2020-12-11 22:29:15.534423 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:29:15.534584 (Thread-1): Began running node model.jaffle_shop.my_second_dbt_model
2020-12-11 22:29:15.535900 (Thread-1): 16:29:15 | 3 of 3 START view model dbt_blake.my_second_dbt_model................ [RUN]
2020-12-11 22:29:15.536307 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 22:29:15.536425 (Thread-1): Compiling model.jaffle_shop.my_second_dbt_model
2020-12-11 22:29:15.545425 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 22:29:15.545952 (Thread-1): finished collecting timing info
2020-12-11 22:29:15.550964 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 22:29:15.551487 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:29:15.551971 (Thread-1): On model.jaffle_shop.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_second_dbt_model"} */


  create or replace view `dbt-demos`.`dbt_blake`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
where id = 1;


2020-12-11 22:29:16.372007 (Thread-1): finished collecting timing info
2020-12-11 22:29:16.372905 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc507005-dbdd-4bd9-a332-e03d61410d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11200a7f0>]}
2020-12-11 22:29:16.374096 (Thread-1): 16:29:16 | 3 of 3 OK created view model dbt_blake.my_second_dbt_model........... [CREATE VIEW in 0.84s]
2020-12-11 22:29:16.374342 (Thread-1): Finished running node model.jaffle_shop.my_second_dbt_model
2020-12-11 22:29:16.376064 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:29:16.376505 (MainThread): 16:29:16 | 
2020-12-11 22:29:16.376629 (MainThread): 16:29:16 | Finished running 1 table model, 2 view models in 4.84s.
2020-12-11 22:29:16.376713 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:29:16.376774 (MainThread): Connection 'model.jaffle_shop.my_second_dbt_model' was properly closed.
2020-12-11 22:29:16.386203 (MainThread): 
2020-12-11 22:29:16.386364 (MainThread): Completed successfully
2020-12-11 22:29:16.386517 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-12-11 22:29:16.386712 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11200aa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111faff70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fafe50>]}
2020-12-11 22:29:16.386948 (MainThread): Flushing usage events
2020-12-11 22:36:29.812327 (MainThread): Running with dbt=0.18.1
2020-12-11 22:36:30.056781 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:36:30.057626 (MainThread): Tracking: tracking
2020-12-11 22:36:30.066203 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bda6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107beb730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107beb6d0>]}
2020-12-11 22:36:30.092149 (MainThread): Partial parsing not enabled
2020-12-11 22:36:30.093473 (MainThread): Parsing macros/etc.sql
2020-12-11 22:36:30.097568 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:36:30.105138 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:36:30.128080 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:36:30.131669 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:36:30.136005 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:36:30.147463 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:36:30.153243 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:36:30.166899 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:36:30.170945 (MainThread): Parsing macros/core.sql
2020-12-11 22:36:30.175595 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:36:30.185511 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:36:30.187520 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:36:30.205538 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:36:30.234505 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:36:30.257216 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:36:30.259494 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:36:30.266208 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:36:30.281331 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:36:30.289211 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:36:30.295796 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:36:30.302203 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:36:30.303665 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:36:30.305219 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:36:30.307219 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:36:30.317492 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:36:30.319814 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:36:30.321874 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:36:30.365070 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:36:30.367475 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:36:30.370043 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:36:30.372709 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:36:30.383291 (MainThread): Partial parsing not enabled
2020-12-11 22:36:30.458451 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:36:30.480186 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 22:36:30.493412 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 22:36:30.738692 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:36:30.739714 (MainThread): 
2020-12-11 22:36:30.740010 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:36:30.744068 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:36:30.744244 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:36:31.169333 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:36:31.169751 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:36:31.170624 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:36:31.457842 (MainThread): 16:36:31 | Concurrency: 1 threads (target='dev')
2020-12-11 22:36:31.458129 (MainThread): 16:36:31 | 
2020-12-11 22:36:31.465548 (Thread-1): Began running node model.jaffle_shop.my_first_dbt_model
2020-12-11 22:36:31.467242 (Thread-1): 16:36:31 | 1 of 3 START table model dbt_blake.my_first_dbt_model................ [RUN]
2020-12-11 22:36:31.467808 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 22:36:31.468033 (Thread-1): Compiling model.jaffle_shop.my_first_dbt_model
2020-12-11 22:36:31.492094 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 22:36:31.493016 (Thread-1): finished collecting timing info
2020-12-11 22:36:31.518368 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:36:31.518922 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:36:31.803072 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 22:36:31.803912 (Thread-1): On model.jaffle_shop.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_first_dbt_model"} */


  create or replace table `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2020-12-11 22:36:33.701363 (Thread-1): finished collecting timing info
2020-12-11 22:36:33.702408 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c9317f5-0052-48fb-a130-819a4bf7ae75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e5bca0>]}
2020-12-11 22:36:33.704754 (Thread-1): 16:36:33 | 1 of 3 OK created table model dbt_blake.my_first_dbt_model........... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.23s]
2020-12-11 22:36:33.705033 (Thread-1): Finished running node model.jaffle_shop.my_first_dbt_model
2020-12-11 22:36:33.705247 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:36:33.707098 (Thread-1): 16:36:33 | 2 of 3 START table model dbt_blake.customers......................... [RUN]
2020-12-11 22:36:33.707528 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:36:33.707674 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:36:33.713342 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50542), raddr=('172.217.12.42', 443)>
2020-12-11 22:36:33.713768 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50543), raddr=('172.217.9.170', 443)>
2020-12-11 22:36:33.714038 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50544), raddr=('172.217.12.42', 443)>
2020-12-11 22:36:33.714273 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50545), raddr=('172.217.9.170', 443)>
2020-12-11 22:36:33.714532 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50547), raddr=('172.217.9.170', 443)>
2020-12-11 22:36:33.714727 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50546), raddr=('172.217.12.42', 443)>
2020-12-11 22:36:33.717513 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:36:33.718001 (Thread-1): finished collecting timing info
2020-12-11 22:36:33.722792 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:36:33.723670 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:36:33.998031 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:36:34.134844 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.customers"
2020-12-11 22:36:34.135829 (Thread-1): On model.jaffle_shop.customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.customers"} */


  create or replace table `dbt-demos`.`dbt_blake`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2020-12-11 22:36:37.019508 (Thread-1): finished collecting timing info
2020-12-11 22:36:37.020727 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c9317f5-0052-48fb-a130-819a4bf7ae75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d99310>]}
2020-12-11 22:36:37.022557 (Thread-1): 16:36:37 | 2 of 3 OK created table model dbt_blake.customers.................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.31s]
2020-12-11 22:36:37.022778 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:36:37.022968 (Thread-1): Began running node model.jaffle_shop.my_second_dbt_model
2020-12-11 22:36:37.024814 (Thread-1): 16:36:37 | 3 of 3 START view model dbt_blake.my_second_dbt_model................ [RUN]
2020-12-11 22:36:37.025449 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 22:36:37.025601 (Thread-1): Compiling model.jaffle_shop.my_second_dbt_model
2020-12-11 22:36:37.035959 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 22:36:37.036581 (Thread-1): finished collecting timing info
2020-12-11 22:36:37.059178 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 22:36:37.059837 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:36:37.060337 (Thread-1): On model.jaffle_shop.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_second_dbt_model"} */


  create or replace view `dbt-demos`.`dbt_blake`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
where id = 1;


2020-12-11 22:36:37.928502 (Thread-1): finished collecting timing info
2020-12-11 22:36:37.929377 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c9317f5-0052-48fb-a130-819a4bf7ae75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eddee0>]}
2020-12-11 22:36:37.930658 (Thread-1): 16:36:37 | 3 of 3 OK created view model dbt_blake.my_second_dbt_model........... [CREATE VIEW in 0.90s]
2020-12-11 22:36:37.930841 (Thread-1): Finished running node model.jaffle_shop.my_second_dbt_model
2020-12-11 22:36:37.932023 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:36:37.932413 (MainThread): 16:36:37 | 
2020-12-11 22:36:37.932564 (MainThread): 16:36:37 | Finished running 2 table models, 1 view model in 7.19s.
2020-12-11 22:36:37.932675 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:36:37.932761 (MainThread): Connection 'model.jaffle_shop.my_second_dbt_model' was properly closed.
2020-12-11 22:36:37.943657 (MainThread): 
2020-12-11 22:36:37.943828 (MainThread): Completed successfully
2020-12-11 22:36:37.943932 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-12-11 22:36:37.944151 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ead6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ded8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ded700>]}
2020-12-11 22:36:37.944338 (MainThread): Flushing usage events
2020-12-11 22:37:58.017033 (MainThread): Running with dbt=0.18.1
2020-12-11 22:37:58.284352 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:37:58.285733 (MainThread): Tracking: tracking
2020-12-11 22:37:58.294606 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110129700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110137790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110137730>]}
2020-12-11 22:37:58.320119 (MainThread): Partial parsing not enabled
2020-12-11 22:37:58.321357 (MainThread): Parsing macros/etc.sql
2020-12-11 22:37:58.325166 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:37:58.332317 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:37:58.353227 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:37:58.356265 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:37:58.359251 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:37:58.370750 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:37:58.376463 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:37:58.390640 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:37:58.394668 (MainThread): Parsing macros/core.sql
2020-12-11 22:37:58.399436 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:37:58.408795 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:37:58.410717 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:37:58.427682 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:37:58.457118 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:37:58.478539 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:37:58.480968 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:37:58.487723 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:37:58.502036 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:37:58.509520 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:37:58.516950 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:37:58.522680 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:37:58.523945 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:37:58.525170 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:37:58.527062 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:37:58.536334 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:37:58.539186 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:37:58.541670 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:37:58.584547 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:37:58.587049 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:37:58.588968 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:37:58.590858 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:37:58.599419 (MainThread): Partial parsing not enabled
2020-12-11 22:37:58.667608 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:37:58.690443 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 22:37:58.702866 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 22:37:58.945725 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:37:58.946537 (MainThread): 
2020-12-11 22:37:58.947010 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:37:58.951374 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:37:58.951561 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:37:59.254500 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:37:59.254716 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:37:59.255414 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:37:59.534492 (MainThread): 16:37:59 | Concurrency: 1 threads (target='dev')
2020-12-11 22:37:59.534684 (MainThread): 16:37:59 | 
2020-12-11 22:37:59.539863 (Thread-1): Began running node model.jaffle_shop.my_first_dbt_model
2020-12-11 22:37:59.540943 (Thread-1): 16:37:59 | 1 of 3 START table model dbt_blake.my_first_dbt_model................ [RUN]
2020-12-11 22:37:59.541275 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 22:37:59.541397 (Thread-1): Compiling model.jaffle_shop.my_first_dbt_model
2020-12-11 22:37:59.559822 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 22:37:59.560299 (Thread-1): finished collecting timing info
2020-12-11 22:37:59.582721 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:37:59.583215 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:37:59.889509 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 22:37:59.890130 (Thread-1): On model.jaffle_shop.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_first_dbt_model"} */


  create or replace table `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2020-12-11 22:38:01.556904 (Thread-1): finished collecting timing info
2020-12-11 22:38:01.557986 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'afa63243-1539-4484-a888-bd870dfa7469', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102def40>]}
2020-12-11 22:38:01.559451 (Thread-1): 16:38:01 | 1 of 3 OK created table model dbt_blake.my_first_dbt_model........... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.02s]
2020-12-11 22:38:01.559639 (Thread-1): Finished running node model.jaffle_shop.my_first_dbt_model
2020-12-11 22:38:01.559823 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:38:01.561566 (Thread-1): 16:38:01 | 2 of 3 START view model dbt_blake.customers.......................... [RUN]
2020-12-11 22:38:01.561991 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:38:01.562188 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:38:01.568918 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50571), raddr=('172.217.12.42', 443)>
2020-12-11 22:38:01.569437 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50572), raddr=('172.217.9.170', 443)>
2020-12-11 22:38:01.569726 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50573), raddr=('172.217.12.42', 443)>
2020-12-11 22:38:01.570005 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50574), raddr=('172.217.9.170', 443)>
2020-12-11 22:38:01.570282 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50576), raddr=('172.217.9.170', 443)>
2020-12-11 22:38:01.570486 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50575), raddr=('172.217.12.42', 443)>
2020-12-11 22:38:01.574502 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:38:01.575082 (Thread-1): finished collecting timing info
2020-12-11 22:38:01.599575 (Thread-1): finished collecting timing info
2020-12-11 22:38:01.600015 (Thread-1): Compilation Error in model customers (models/customers.sql)
  Trying to create view `dbt-demos`.`dbt_blake`.`customers`, but it currently exists as a table. Either drop `dbt-demos`.`dbt_blake`.`customers` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model customers (models/customers.sql)
Traceback (most recent call last):
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/exceptions.py", line 980, in inner
    raise exc
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/exceptions.py", line 977, in inner
    return func(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/exceptions.py", line 641, in relation_wrong_type
    raise_compiler_error(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model customers (models/customers.sql)
  Trying to create view `dbt-demos`.`dbt_blake`.`customers`, but it currently exists as a table. Either drop `dbt-demos`.`dbt_blake`.`customers` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model customers (models/customers.sql)
2020-12-11 22:38:01.605951 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'afa63243-1539-4484-a888-bd870dfa7469', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11051feb0>]}
2020-12-11 22:38:01.607067 (Thread-1): 16:38:01 | 2 of 3 ERROR creating view model dbt_blake.customers................. [ERROR in 0.04s]
2020-12-11 22:38:01.607185 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:38:01.607298 (Thread-1): Began running node model.jaffle_shop.my_second_dbt_model
2020-12-11 22:38:01.608203 (Thread-1): 16:38:01 | 3 of 3 START view model dbt_blake.my_second_dbt_model................ [RUN]
2020-12-11 22:38:01.608455 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 22:38:01.608542 (Thread-1): Compiling model.jaffle_shop.my_second_dbt_model
2020-12-11 22:38:01.617159 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 22:38:01.617971 (Thread-1): finished collecting timing info
2020-12-11 22:38:01.626666 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 22:38:01.627227 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:38:01.627609 (Thread-1): On model.jaffle_shop.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_second_dbt_model"} */


  create or replace view `dbt-demos`.`dbt_blake`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
where id = 1;


2020-12-11 22:38:02.647961 (Thread-1): finished collecting timing info
2020-12-11 22:38:02.649096 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'afa63243-1539-4484-a888-bd870dfa7469', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11051feb0>]}
2020-12-11 22:38:02.650724 (Thread-1): 16:38:02 | 3 of 3 OK created view model dbt_blake.my_second_dbt_model........... [CREATE VIEW in 1.04s]
2020-12-11 22:38:02.650936 (Thread-1): Finished running node model.jaffle_shop.my_second_dbt_model
2020-12-11 22:38:02.652990 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:38:02.653523 (MainThread): 16:38:02 | 
2020-12-11 22:38:02.653727 (MainThread): 16:38:02 | Finished running 1 table model, 2 view models in 3.71s.
2020-12-11 22:38:02.653874 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:38:02.653986 (MainThread): Connection 'model.jaffle_shop.my_second_dbt_model' was properly closed.
2020-12-11 22:38:02.668137 (MainThread): 
2020-12-11 22:38:02.668438 (MainThread): Completed with 1 error and 0 warnings:
2020-12-11 22:38:02.668635 (MainThread): 
2020-12-11 22:38:02.668835 (MainThread): Compilation Error in model customers (models/customers.sql)
2020-12-11 22:38:02.669007 (MainThread):   Trying to create view `dbt-demos`.`dbt_blake`.`customers`, but it currently exists as a table. Either drop `dbt-demos`.`dbt_blake`.`customers` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2020-12-11 22:38:02.669153 (MainThread):   
2020-12-11 22:38:02.669265 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2020-12-11 22:38:02.669499 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2020-12-11 22:38:02.669664 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2020-12-11 22:38:02.669838 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2020-12-11 22:38:02.669939 (MainThread):   > called by model customers (models/customers.sql)
2020-12-11 22:38:02.670041 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2020-12-11 22:38:02.670257 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110307670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110429ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110429df0>]}
2020-12-11 22:38:02.670588 (MainThread): Flushing usage events
2020-12-11 22:38:20.970116 (MainThread): Running with dbt=0.18.1
2020-12-11 22:38:21.166778 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:38:21.168109 (MainThread): Tracking: tracking
2020-12-11 22:38:21.177314 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc2cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc396a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc39640>]}
2020-12-11 22:38:21.203533 (MainThread): Partial parsing not enabled
2020-12-11 22:38:21.204697 (MainThread): Parsing macros/etc.sql
2020-12-11 22:38:21.208237 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:38:21.215229 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:38:21.236044 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:38:21.238943 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:38:21.242145 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:38:21.253686 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:38:21.258615 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:38:21.271968 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:38:21.274943 (MainThread): Parsing macros/core.sql
2020-12-11 22:38:21.279027 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:38:21.288531 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:38:21.290624 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:38:21.307788 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:38:21.336686 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:38:21.358820 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:38:21.360830 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:38:21.367170 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:38:21.381728 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:38:21.389194 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:38:21.395681 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:38:21.400810 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:38:21.401982 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:38:21.403345 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:38:21.405022 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:38:21.414498 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:38:21.416834 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:38:21.418866 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:38:21.462069 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:38:21.464033 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:38:21.465619 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:38:21.467558 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:38:21.476447 (MainThread): Partial parsing not enabled
2020-12-11 22:38:21.544620 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:38:21.566390 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 22:38:21.579120 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 22:38:21.807117 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:38:21.808165 (MainThread): 
2020-12-11 22:38:21.808565 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:38:21.812332 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:38:21.812517 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:38:22.088614 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:38:22.088932 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:38:22.089620 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:38:22.349928 (MainThread): 16:38:22 | Concurrency: 1 threads (target='dev')
2020-12-11 22:38:22.350279 (MainThread): 16:38:22 | 
2020-12-11 22:38:22.356204 (Thread-1): Began running node model.jaffle_shop.my_first_dbt_model
2020-12-11 22:38:22.357956 (Thread-1): 16:38:22 | 1 of 3 START table model dbt_blake.my_first_dbt_model................ [RUN]
2020-12-11 22:38:22.358568 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_first_dbt_model".
2020-12-11 22:38:22.358771 (Thread-1): Compiling model.jaffle_shop.my_first_dbt_model
2020-12-11 22:38:22.381262 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 22:38:22.381752 (Thread-1): finished collecting timing info
2020-12-11 22:38:22.404175 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:38:22.404689 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:38:22.732378 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_first_dbt_model"
2020-12-11 22:38:22.732880 (Thread-1): On model.jaffle_shop.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_first_dbt_model"} */


  create or replace table `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2020-12-11 22:38:24.410618 (Thread-1): finished collecting timing info
2020-12-11 22:38:24.411829 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acdeb413-f65a-4b31-a41e-a79e6b4dcde7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce43190>]}
2020-12-11 22:38:24.413708 (Thread-1): 16:38:24 | 1 of 3 OK created table model dbt_blake.my_first_dbt_model........... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.05s]
2020-12-11 22:38:24.413905 (Thread-1): Finished running node model.jaffle_shop.my_first_dbt_model
2020-12-11 22:38:24.414088 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:38:24.415958 (Thread-1): 16:38:24 | 2 of 3 START view model dbt_blake.customers.......................... [RUN]
2020-12-11 22:38:24.416406 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:38:24.416567 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:38:24.422017 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50586), raddr=('172.217.12.42', 443)>
2020-12-11 22:38:24.422347 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50587), raddr=('172.217.9.170', 443)>
2020-12-11 22:38:24.422666 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50588), raddr=('172.217.12.42', 443)>
2020-12-11 22:38:24.422939 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50589), raddr=('172.217.9.170', 443)>
2020-12-11 22:38:24.423233 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50591), raddr=('172.217.9.170', 443)>
2020-12-11 22:38:24.423482 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50590), raddr=('172.217.12.42', 443)>
2020-12-11 22:38:24.428187 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:38:24.428727 (Thread-1): finished collecting timing info
2020-12-11 22:38:24.453222 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:38:24.453750 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:38:24.768483 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.customers"
2020-12-11 22:38:24.769448 (Thread-1): On model.jaffle_shop.customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.customers"} */


  create or replace view `dbt-demos`.`dbt_blake`.`customers`
  OPTIONS()
  as 


with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2020-12-11 22:38:25.527822 (Thread-1): finished collecting timing info
2020-12-11 22:38:25.528908 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acdeb413-f65a-4b31-a41e-a79e6b4dcde7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce31130>]}
2020-12-11 22:38:25.530583 (Thread-1): 16:38:25 | 2 of 3 OK created view model dbt_blake.customers..................... [CREATE VIEW in 1.11s]
2020-12-11 22:38:25.530801 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:38:25.531018 (Thread-1): Began running node model.jaffle_shop.my_second_dbt_model
2020-12-11 22:38:25.533155 (Thread-1): 16:38:25 | 3 of 3 START view model dbt_blake.my_second_dbt_model................ [RUN]
2020-12-11 22:38:25.533817 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.my_second_dbt_model".
2020-12-11 22:38:25.534008 (Thread-1): Compiling model.jaffle_shop.my_second_dbt_model
2020-12-11 22:38:25.545306 (Thread-1): Writing injected SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 22:38:25.545938 (Thread-1): finished collecting timing info
2020-12-11 22:38:25.551301 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.my_second_dbt_model"
2020-12-11 22:38:25.551948 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:38:25.552513 (Thread-1): On model.jaffle_shop.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.my_second_dbt_model"} */


  create or replace view `dbt-demos`.`dbt_blake`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-demos`.`dbt_blake`.`my_first_dbt_model`
where id = 1;


2020-12-11 22:38:26.430371 (Thread-1): finished collecting timing info
2020-12-11 22:38:26.431652 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acdeb413-f65a-4b31-a41e-a79e6b4dcde7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cde54c0>]}
2020-12-11 22:38:26.433635 (Thread-1): 16:38:26 | 3 of 3 OK created view model dbt_blake.my_second_dbt_model........... [CREATE VIEW in 0.90s]
2020-12-11 22:38:26.433873 (Thread-1): Finished running node model.jaffle_shop.my_second_dbt_model
2020-12-11 22:38:26.435804 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:38:26.436316 (MainThread): 16:38:26 | 
2020-12-11 22:38:26.436514 (MainThread): 16:38:26 | Finished running 1 table model, 2 view models in 4.63s.
2020-12-11 22:38:26.436665 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:38:26.436779 (MainThread): Connection 'model.jaffle_shop.my_second_dbt_model' was properly closed.
2020-12-11 22:38:26.450850 (MainThread): 
2020-12-11 22:38:26.451110 (MainThread): Completed successfully
2020-12-11 22:38:26.451238 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-12-11 22:38:26.451421 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd7190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda8c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda8e20>]}
2020-12-11 22:38:26.451633 (MainThread): Flushing usage events
2020-12-11 22:40:11.703125 (MainThread): Running with dbt=0.18.1
2020-12-11 22:40:11.935762 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:40:11.937142 (MainThread): Tracking: tracking
2020-12-11 22:40:11.945528 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085df730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085ec7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085ec760>]}
2020-12-11 22:40:11.970008 (MainThread): Partial parsing not enabled
2020-12-11 22:40:11.971367 (MainThread): Parsing macros/etc.sql
2020-12-11 22:40:11.975521 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:40:11.982287 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:40:12.002193 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:40:12.005299 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:40:12.008804 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:40:12.019630 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:40:12.024201 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:40:12.037288 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:40:12.041235 (MainThread): Parsing macros/core.sql
2020-12-11 22:40:12.045936 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:40:12.055907 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:40:12.057911 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:40:12.075289 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:40:12.104107 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:40:12.125909 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:40:12.128026 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:40:12.134713 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:40:12.149172 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:40:12.156481 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:40:12.162785 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:40:12.168267 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:40:12.169443 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:40:12.170641 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:40:12.172756 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:40:12.182015 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:40:12.184686 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:40:12.187112 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:40:12.230255 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:40:12.232601 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:40:12.234397 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:40:12.236358 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:40:12.245656 (MainThread): Partial parsing not enabled
2020-12-11 22:40:12.314251 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:40:12.452654 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:40:12.453169 (MainThread): 
2020-12-11 22:40:12.453464 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:40:12.454848 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:40:12.454990 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:40:12.793591 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:40:12.794197 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:40:12.795087 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:40:13.084579 (MainThread): 16:40:13 | Concurrency: 1 threads (target='dev')
2020-12-11 22:40:13.084913 (MainThread): 16:40:13 | 
2020-12-11 22:40:13.092141 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:40:13.094090 (Thread-1): 16:40:13 | 1 of 1 START view model dbt_blake.customers.......................... [RUN]
2020-12-11 22:40:13.094497 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:40:13.094659 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:40:13.115946 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:40:13.116432 (Thread-1): finished collecting timing info
2020-12-11 22:40:13.148357 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.customers"
2020-12-11 22:40:13.148937 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:40:13.149646 (Thread-1): On model.jaffle_shop.customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.customers"} */


  create or replace view `dbt-demos`.`dbt_blake`.`customers`
  OPTIONS()
  as 


with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2020-12-11 22:40:13.155104 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50610), raddr=('172.217.12.42', 443)>
2020-12-11 22:40:13.155302 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50611), raddr=('172.217.9.170', 443)>
2020-12-11 22:40:13.155473 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50613), raddr=('172.217.9.170', 443)>
2020-12-11 22:40:13.155652 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50612), raddr=('172.217.12.42', 443)>
2020-12-11 22:40:14.145390 (Thread-1): finished collecting timing info
2020-12-11 22:40:14.146386 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2e9a5b1-9775-4c55-81d9-f19ec39f3f1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10880f9d0>]}
2020-12-11 22:40:14.148321 (Thread-1): 16:40:14 | 1 of 1 OK created view model dbt_blake.customers..................... [CREATE VIEW in 1.05s]
2020-12-11 22:40:14.148577 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:40:14.150456 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:40:14.151092 (MainThread): 16:40:14 | 
2020-12-11 22:40:14.151290 (MainThread): 16:40:14 | Finished running 1 view model in 1.70s.
2020-12-11 22:40:14.151469 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:40:14.151624 (MainThread): Connection 'model.jaffle_shop.customers' was properly closed.
2020-12-11 22:40:14.156887 (MainThread): 
2020-12-11 22:40:14.157098 (MainThread): Completed successfully
2020-12-11 22:40:14.157243 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-12-11 22:40:14.157428 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087f6e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087f6fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108897fd0>]}
2020-12-11 22:40:14.157653 (MainThread): Flushing usage events
2020-12-11 22:43:56.650355 (MainThread): Running with dbt=0.18.1
2020-12-11 22:43:56.879037 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:43:56.880408 (MainThread): Tracking: tracking
2020-12-11 22:43:56.889611 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11310fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11311e700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11311e6a0>]}
2020-12-11 22:43:56.913902 (MainThread): Partial parsing not enabled
2020-12-11 22:43:56.915381 (MainThread): Parsing macros/etc.sql
2020-12-11 22:43:56.919181 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:43:56.926822 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:43:56.946387 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:43:56.949932 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:43:56.953227 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:43:56.963850 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:43:56.968797 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:43:56.981895 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:43:56.985335 (MainThread): Parsing macros/core.sql
2020-12-11 22:43:56.989862 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:43:56.999023 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:43:57.000970 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:43:57.017491 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:43:57.045485 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:43:57.066631 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:43:57.068777 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:43:57.075025 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:43:57.089530 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:43:57.096730 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:43:57.103190 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:43:57.108242 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:43:57.109365 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:43:57.110607 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:43:57.112480 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:43:57.121771 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:43:57.124437 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:43:57.126522 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:43:57.168242 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:43:57.170316 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:43:57.172081 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:43:57.173924 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:43:57.182110 (MainThread): Partial parsing not enabled
2020-12-11 22:43:57.250057 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:43:57.268809 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:43:57.281534 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:43:57.413061 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:43:57.413796 (MainThread): 
2020-12-11 22:43:57.414165 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:43:57.417753 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:43:57.417913 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:43:57.794735 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:43:57.795203 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:43:57.796225 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:43:58.087289 (MainThread): 16:43:58 | Concurrency: 1 threads (target='dev')
2020-12-11 22:43:58.087643 (MainThread): 16:43:58 | 
2020-12-11 22:43:58.095491 (MainThread): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50655), raddr=('172.217.9.138', 443)>
2020-12-11 22:43:58.095925 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50656), raddr=('172.217.9.170', 443)>
2020-12-11 22:43:58.096799 (Thread-1): Began running node model.jaffle_shop.stg_customers
2020-12-11 22:43:58.098735 (Thread-1): 16:43:58 | 1 of 3 START table model dbt_blake.stg_customers..................... [RUN]
2020-12-11 22:43:58.099209 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:43:58.099368 (Thread-1): Compiling model.jaffle_shop.stg_customers
2020-12-11 22:43:58.119583 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:43:58.120245 (Thread-1): finished collecting timing info
2020-12-11 22:43:58.160014 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:43:58.160524 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:43:58.160972 (Thread-1): On model.jaffle_shop.stg_customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_customers"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2020-12-11 22:44:00.289054 (Thread-1): finished collecting timing info
2020-12-11 22:44:00.290153 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5cfdefc7-e240-49b4-b689-2e89ba5e7a07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113597460>]}
2020-12-11 22:44:00.291921 (Thread-1): 16:44:00 | 1 of 3 OK created table model dbt_blake.stg_customers................ [CREATE TABLE (100.0 rows, 1.9 KB processed) in 2.19s]
2020-12-11 22:44:00.292231 (Thread-1): Finished running node model.jaffle_shop.stg_customers
2020-12-11 22:44:00.292499 (Thread-1): Began running node model.jaffle_shop.stg_orders
2020-12-11 22:44:00.294253 (Thread-1): 16:44:00 | 2 of 3 START table model dbt_blake.stg_orders........................ [RUN]
2020-12-11 22:44:00.295034 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:44:00.295255 (Thread-1): Compiling model.jaffle_shop.stg_orders
2020-12-11 22:44:00.303167 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:44:00.303742 (Thread-1): finished collecting timing info
2020-12-11 22:44:00.309109 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:44:00.309748 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:44:00.310379 (Thread-1): On model.jaffle_shop.stg_orders: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_orders"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2020-12-11 22:44:02.737724 (Thread-1): finished collecting timing info
2020-12-11 22:44:02.739223 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5cfdefc7-e240-49b4-b689-2e89ba5e7a07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11351ee80>]}
2020-12-11 22:44:02.741223 (Thread-1): 16:44:02 | 2 of 3 OK created table model dbt_blake.stg_orders................... [CREATE TABLE (99.0 rows, 3.3 KB processed) in 2.44s]
2020-12-11 22:44:02.741670 (Thread-1): Finished running node model.jaffle_shop.stg_orders
2020-12-11 22:44:02.742797 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:44:02.744995 (Thread-1): 16:44:02 | 3 of 3 START view model dbt_blake.customers.......................... [RUN]
2020-12-11 22:44:02.745685 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:44:02.745892 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:44:02.749812 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50661), raddr=('172.217.9.138', 443)>
2020-12-11 22:44:02.750117 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50662), raddr=('172.217.9.170', 443)>
2020-12-11 22:44:02.760196 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:44:02.761069 (Thread-1): finished collecting timing info
2020-12-11 22:44:02.782270 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.customers"
2020-12-11 22:44:02.782786 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:44:02.783352 (Thread-1): On model.jaffle_shop.customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.customers"} */


  create or replace view `dbt-demos`.`dbt_blake`.`customers`
  OPTIONS()
  as 


with customers as (

    select * from `dbt-demos`.`dbt_blake`.`stg_customers`
),

orders as (

    select * from `dbt-demos`.`dbt_blake`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2020-12-11 22:44:03.615402 (Thread-1): finished collecting timing info
2020-12-11 22:44:03.616660 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5cfdefc7-e240-49b4-b689-2e89ba5e7a07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133b26d0>]}
2020-12-11 22:44:03.618654 (Thread-1): 16:44:03 | 3 of 3 OK created view model dbt_blake.customers..................... [CREATE VIEW in 0.87s]
2020-12-11 22:44:03.618922 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:44:03.620774 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:44:03.621312 (MainThread): 16:44:03 | 
2020-12-11 22:44:03.621552 (MainThread): 16:44:03 | Finished running 2 table models, 1 view model in 6.21s.
2020-12-11 22:44:03.621715 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:44:03.621958 (MainThread): Connection 'model.jaffle_shop.customers' was properly closed.
2020-12-11 22:44:03.635918 (MainThread): 
2020-12-11 22:44:03.636133 (MainThread): Completed successfully
2020-12-11 22:44:03.636278 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-12-11 22:44:03.636488 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113426a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11356d940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11356d8e0>]}
2020-12-11 22:44:03.636738 (MainThread): Flushing usage events
2020-12-11 22:45:28.387525 (MainThread): Running with dbt=0.18.1
2020-12-11 22:45:28.614559 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['stg_orders'], partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:45:28.615634 (MainThread): Tracking: tracking
2020-12-11 22:45:28.623970 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113c3fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113d16a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113d1640>]}
2020-12-11 22:45:28.647802 (MainThread): Partial parsing not enabled
2020-12-11 22:45:28.649107 (MainThread): Parsing macros/etc.sql
2020-12-11 22:45:28.652742 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:45:28.659535 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:45:28.679156 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:45:28.682252 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:45:28.685450 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:45:28.695946 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:45:28.700560 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:45:28.714230 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:45:28.717396 (MainThread): Parsing macros/core.sql
2020-12-11 22:45:28.721420 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:45:28.730568 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:45:28.732675 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:45:28.751053 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:45:28.782739 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:45:28.803265 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:45:28.805734 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:45:28.812312 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:45:28.826153 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:45:28.832981 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:45:28.839907 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:45:28.845561 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:45:28.846779 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:45:28.848023 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:45:28.849887 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:45:28.858982 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:45:28.861115 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:45:28.863140 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:45:28.905067 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:45:28.907259 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:45:28.908895 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:45:28.910773 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:45:28.918819 (MainThread): Partial parsing not enabled
2020-12-11 22:45:28.984634 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:45:29.005078 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:45:29.017795 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:45:29.149580 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:45:29.150167 (MainThread): 
2020-12-11 22:45:29.150479 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:45:29.151742 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:45:29.151869 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:45:29.415643 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:45:29.416096 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:45:29.417088 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:45:29.742900 (MainThread): 16:45:29 | Concurrency: 1 threads (target='dev')
2020-12-11 22:45:29.743243 (MainThread): 16:45:29 | 
2020-12-11 22:45:29.750250 (MainThread): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50682), raddr=('172.217.9.138', 443)>
2020-12-11 22:45:29.750608 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50683), raddr=('172.217.9.170', 443)>
2020-12-11 22:45:29.751675 (Thread-1): Began running node model.jaffle_shop.stg_orders
2020-12-11 22:45:29.753173 (Thread-1): 16:45:29 | 1 of 1 START table model dbt_blake.stg_orders........................ [RUN]
2020-12-11 22:45:29.753697 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:45:29.753893 (Thread-1): Compiling model.jaffle_shop.stg_orders
2020-12-11 22:45:29.773197 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:45:29.773854 (Thread-1): finished collecting timing info
2020-12-11 22:45:29.795611 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:45:29.796216 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:45:30.095749 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:45:30.096291 (Thread-1): On model.jaffle_shop.stg_orders: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_orders"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2020-12-11 22:45:32.005445 (Thread-1): finished collecting timing info
2020-12-11 22:45:32.006586 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49574b4c-9dc2-462d-87fd-076e0a23cffa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11288b700>]}
2020-12-11 22:45:32.008177 (Thread-1): 16:45:32 | 1 of 1 OK created table model dbt_blake.stg_orders................... [CREATE TABLE (99.0 rows, 3.3 KB processed) in 2.25s]
2020-12-11 22:45:32.008364 (Thread-1): Finished running node model.jaffle_shop.stg_orders
2020-12-11 22:45:32.010162 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:45:32.010618 (MainThread): 16:45:32 | 
2020-12-11 22:45:32.010802 (MainThread): 16:45:32 | Finished running 1 table model in 2.86s.
2020-12-11 22:45:32.010936 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:45:32.011035 (MainThread): Connection 'model.jaffle_shop.stg_orders' was properly closed.
2020-12-11 22:45:32.015827 (MainThread): 
2020-12-11 22:45:32.016021 (MainThread): Completed successfully
2020-12-11 22:45:32.016152 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-12-11 22:45:32.016353 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111691670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112852c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112852be0>]}
2020-12-11 22:45:32.016569 (MainThread): Flushing usage events
2020-12-11 22:46:26.490936 (MainThread): Running with dbt=0.18.1
2020-12-11 22:46:26.679208 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:46:26.680273 (MainThread): Tracking: tracking
2020-12-11 22:46:26.688249 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055546a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105563730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055636d0>]}
2020-12-11 22:46:26.712776 (MainThread): Partial parsing not enabled
2020-12-11 22:46:26.713854 (MainThread): Parsing macros/etc.sql
2020-12-11 22:46:26.717048 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:46:26.725092 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:46:26.744294 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:46:26.747426 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:46:26.750442 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:46:26.760759 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:46:26.765303 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:46:26.777787 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:46:26.781081 (MainThread): Parsing macros/core.sql
2020-12-11 22:46:26.784658 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:46:26.793562 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:46:26.795510 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:46:26.811524 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:46:26.840452 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:46:26.860866 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:46:26.863081 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:46:26.869381 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:46:26.882508 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:46:26.889262 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:46:26.895639 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:46:26.900620 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:46:26.901625 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:46:26.902706 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:46:26.904327 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:46:26.912978 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:46:26.915161 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:46:26.916862 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:46:26.957505 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:46:26.959713 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:46:26.961371 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:46:26.963159 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:46:26.971094 (MainThread): Partial parsing not enabled
2020-12-11 22:46:27.035565 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:46:27.056808 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:46:27.066110 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:46:27.199090 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:46:27.199736 (MainThread): 
2020-12-11 22:46:27.200252 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:46:27.203878 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:46:27.204032 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:46:27.523221 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:46:27.523651 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:46:27.524732 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:46:27.842362 (MainThread): 16:46:27 | Concurrency: 1 threads (target='dev')
2020-12-11 22:46:27.842647 (MainThread): 16:46:27 | 
2020-12-11 22:46:27.847601 (Thread-1): Began running node model.jaffle_shop.stg_customers
2020-12-11 22:46:27.849170 (Thread-1): 16:46:27 | 1 of 3 START table model dbt_blake.stg_customers..................... [RUN]
2020-12-11 22:46:27.849574 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:46:27.849732 (Thread-1): Compiling model.jaffle_shop.stg_customers
2020-12-11 22:46:27.859721 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50693), raddr=('172.217.9.138', 443)>
2020-12-11 22:46:27.860096 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50695), raddr=('172.217.9.138', 443)>
2020-12-11 22:46:27.860440 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50694), raddr=('172.217.9.170', 443)>
2020-12-11 22:46:27.860760 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50696), raddr=('172.217.9.170', 443)>
2020-12-11 22:46:27.870665 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:46:27.871334 (Thread-1): finished collecting timing info
2020-12-11 22:46:27.893824 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:46:27.894459 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:46:28.187747 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:46:28.188479 (Thread-1): On model.jaffle_shop.stg_customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_customers"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2020-12-11 22:46:30.434642 (Thread-1): finished collecting timing info
2020-12-11 22:46:30.435972 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a6d4088-ebc4-4d81-b0b8-1cca8b8228c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c1e20>]}
2020-12-11 22:46:30.438423 (Thread-1): 16:46:30 | 1 of 3 OK created table model dbt_blake.stg_customers................ [CREATE TABLE (100.0 rows, 1.9 KB processed) in 2.59s]
2020-12-11 22:46:30.438675 (Thread-1): Finished running node model.jaffle_shop.stg_customers
2020-12-11 22:46:30.438895 (Thread-1): Began running node model.jaffle_shop.stg_orders
2020-12-11 22:46:30.440576 (Thread-1): 16:46:30 | 2 of 3 START table model dbt_blake.stg_orders........................ [RUN]
2020-12-11 22:46:30.441021 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:46:30.441192 (Thread-1): Compiling model.jaffle_shop.stg_orders
2020-12-11 22:46:30.449310 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:46:30.449883 (Thread-1): finished collecting timing info
2020-12-11 22:46:30.454515 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:46:30.455083 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:46:30.725193 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:46:30.726511 (Thread-1): On model.jaffle_shop.stg_orders: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_orders"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2020-12-11 22:46:33.034765 (Thread-1): finished collecting timing info
2020-12-11 22:46:33.036423 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a6d4088-ebc4-4d81-b0b8-1cca8b8228c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a4aee0>]}
2020-12-11 22:46:33.038555 (Thread-1): 16:46:33 | 2 of 3 OK created table model dbt_blake.stg_orders................... [CREATE TABLE (99.0 rows, 3.3 KB processed) in 2.60s]
2020-12-11 22:46:33.038822 (Thread-1): Finished running node model.jaffle_shop.stg_orders
2020-12-11 22:46:33.040006 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:46:33.041965 (Thread-1): 16:46:33 | 3 of 3 START view model dbt_blake.customers.......................... [RUN]
2020-12-11 22:46:33.042720 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:46:33.042988 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:46:33.056682 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:46:33.057387 (Thread-1): finished collecting timing info
2020-12-11 22:46:33.080499 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.customers"
2020-12-11 22:46:33.080995 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:46:33.081463 (Thread-1): On model.jaffle_shop.customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.customers"} */


  create or replace view `dbt-demos`.`dbt_blake`.`customers`
  OPTIONS()
  as 


with customers as (

    select * from `dbt-demos`.`dbt_blake`.`stg_customers`
),

orders as (

    select * from `dbt-demos`.`dbt_blake`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2020-12-11 22:46:33.982022 (Thread-1): finished collecting timing info
2020-12-11 22:46:33.983549 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a6d4088-ebc4-4d81-b0b8-1cca8b8228c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057f2130>]}
2020-12-11 22:46:33.985593 (Thread-1): 16:46:33 | 3 of 3 OK created view model dbt_blake.customers..................... [CREATE VIEW in 0.94s]
2020-12-11 22:46:33.985816 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:46:33.987457 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:46:33.987938 (MainThread): 16:46:33 | 
2020-12-11 22:46:33.988129 (MainThread): 16:46:33 | Finished running 2 table models, 1 view model in 6.79s.
2020-12-11 22:46:33.988277 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:46:33.988388 (MainThread): Connection 'model.jaffle_shop.customers' was properly closed.
2020-12-11 22:46:34.001372 (MainThread): 
2020-12-11 22:46:34.001590 (MainThread): Completed successfully
2020-12-11 22:46:34.001728 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-12-11 22:46:34.001934 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057daeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105881520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059ac730>]}
2020-12-11 22:46:34.002163 (MainThread): Flushing usage events
2020-12-11 22:48:21.489592 (MainThread): Running with dbt=0.18.1
2020-12-11 22:48:21.725996 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:48:21.727068 (MainThread): Tracking: tracking
2020-12-11 22:48:21.735319 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd1bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd296d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd29670>]}
2020-12-11 22:48:21.766126 (MainThread): Partial parsing not enabled
2020-12-11 22:48:21.767617 (MainThread): Parsing macros/etc.sql
2020-12-11 22:48:21.772309 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:48:21.779122 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:48:21.798777 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:48:21.802012 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:48:21.806406 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:48:21.817232 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:48:21.822112 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:48:21.835104 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:48:21.838674 (MainThread): Parsing macros/core.sql
2020-12-11 22:48:21.843194 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:48:21.852673 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:48:21.854626 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:48:21.871714 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:48:21.900321 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:48:21.921954 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:48:21.924075 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:48:21.930357 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:48:21.945134 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:48:21.952474 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:48:21.958851 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:48:21.964048 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:48:21.965447 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:48:21.966765 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:48:21.968936 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:48:21.979596 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:48:21.981924 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:48:21.984728 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:48:22.029291 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:48:22.031687 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:48:22.033582 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:48:22.035667 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:48:22.045188 (MainThread): Partial parsing not enabled
2020-12-11 22:48:22.114924 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:48:22.138134 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:48:22.150005 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:48:22.160099 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:48:22.300097 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:48:22.300846 (MainThread): 
2020-12-11 22:48:22.301200 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:48:22.306219 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:48:22.306561 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:48:22.596554 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:48:22.596924 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:48:22.597810 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:48:22.622257 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50729), raddr=('172.217.9.138', 443)>
2020-12-11 22:48:22.622659 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50730), raddr=('172.217.9.170', 443)>
2020-12-11 22:48:22.889306 (MainThread): 16:48:22 | Concurrency: 1 threads (target='dev')
2020-12-11 22:48:22.889590 (MainThread): 16:48:22 | 
2020-12-11 22:48:22.895810 (Thread-1): Began running node model.jaffle_shop.stg_customers
2020-12-11 22:48:22.897310 (Thread-1): 16:48:22 | 1 of 4 START table model dbt_blake.stg_customers..................... [RUN]
2020-12-11 22:48:22.897915 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:48:22.898145 (Thread-1): Compiling model.jaffle_shop.stg_customers
2020-12-11 22:48:22.916864 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:48:22.917645 (Thread-1): finished collecting timing info
2020-12-11 22:48:22.939812 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:48:22.940421 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:48:23.210666 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:48:23.211189 (Thread-1): On model.jaffle_shop.stg_customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_customers"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2020-12-11 22:48:25.491056 (Thread-1): finished collecting timing info
2020-12-11 22:48:25.492028 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c9f309d-9105-479a-8c22-2d7013f50900', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d19afd0>]}
2020-12-11 22:48:25.493396 (Thread-1): 16:48:25 | 1 of 4 OK created table model dbt_blake.stg_customers................ [CREATE TABLE (100.0 rows, 1.9 KB processed) in 2.59s]
2020-12-11 22:48:25.493555 (Thread-1): Finished running node model.jaffle_shop.stg_customers
2020-12-11 22:48:25.493709 (Thread-1): Began running node model.jaffle_shop.stg_orders
2020-12-11 22:48:25.495271 (Thread-1): 16:48:25 | 2 of 4 START table model dbt_blake.stg_orders........................ [RUN]
2020-12-11 22:48:25.495652 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:48:25.495788 (Thread-1): Compiling model.jaffle_shop.stg_orders
2020-12-11 22:48:25.502968 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:48:25.503552 (Thread-1): finished collecting timing info
2020-12-11 22:48:25.508963 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:48:25.509787 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:48:25.772082 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:48:25.774230 (Thread-1): On model.jaffle_shop.stg_orders: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_orders"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2020-12-11 22:48:27.793671 (Thread-1): finished collecting timing info
2020-12-11 22:48:27.794575 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c9f309d-9105-479a-8c22-2d7013f50900', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2051f0>]}
2020-12-11 22:48:27.795891 (Thread-1): 16:48:27 | 2 of 4 OK created table model dbt_blake.stg_orders................... [CREATE TABLE (99.0 rows, 3.3 KB processed) in 2.30s]
2020-12-11 22:48:27.796055 (Thread-1): Finished running node model.jaffle_shop.stg_orders
2020-12-11 22:48:27.796876 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:48:27.798378 (Thread-1): 16:48:27 | 3 of 4 START view model dbt_blake.customers.......................... [RUN]
2020-12-11 22:48:27.798790 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:48:27.798954 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:48:27.808623 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:48:27.809126 (Thread-1): finished collecting timing info
2020-12-11 22:48:27.822196 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50735), raddr=('172.217.9.170', 443)>
2020-12-11 22:48:27.822484 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50734), raddr=('172.217.9.138', 443)>
2020-12-11 22:48:27.822719 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50736), raddr=('172.217.9.138', 443)>
2020-12-11 22:48:27.822861 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50737), raddr=('172.217.9.170', 443)>
2020-12-11 22:48:27.831808 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.customers"
2020-12-11 22:48:27.832383 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:48:27.832831 (Thread-1): On model.jaffle_shop.customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.customers"} */


  create or replace view `dbt-demos`.`dbt_blake`.`customers`
  OPTIONS()
  as 


with customers as (

    select * from `dbt-demos`.`dbt_blake`.`stg_customers`
),

orders as (

    select * from `dbt-demos`.`dbt_blake`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2020-12-11 22:48:28.695891 (Thread-1): finished collecting timing info
2020-12-11 22:48:28.696985 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c9f309d-9105-479a-8c22-2d7013f50900', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf349a0>]}
2020-12-11 22:48:28.698851 (Thread-1): 16:48:28 | 3 of 4 OK created view model dbt_blake.customers..................... [CREATE VIEW in 0.90s]
2020-12-11 22:48:28.699124 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:48:28.700011 (Thread-1): Began running node model.jaffle_shop.bad_customers
2020-12-11 22:48:28.701435 (Thread-1): 16:48:28 | 4 of 4 START table model dbt_blake.bad_customers..................... [RUN]
2020-12-11 22:48:28.701835 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:48:28.701980 (Thread-1): Compiling model.jaffle_shop.bad_customers
2020-12-11 22:48:28.712458 (Thread-1): Writing injected SQL for node "model.jaffle_shop.bad_customers"
2020-12-11 22:48:28.713021 (Thread-1): finished collecting timing info
2020-12-11 22:48:28.718775 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.bad_customers"
2020-12-11 22:48:28.719404 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:48:28.719973 (Thread-1): On model.jaffle_shop.bad_customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.bad_customers"} */


  create or replace table `dbt-demos`.`dbt_blake`.`bad_customers`
  
  
  OPTIONS()
  as (
    select * from `dbt-demos`.`dbt_blake`.`customers` where num_orders = 0
  );
    
2020-12-11 22:48:29.516787 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dbt-demos/queries/57e1a071-e02b-4759-92a1-9cbae1762438?maxResults=0&location=US: Unrecognized name: num_orders at [9:61]')
2020-12-11 22:48:30.898379 (Thread-1): finished collecting timing info
2020-12-11 22:48:30.899465 (Thread-1): Database Error in model bad_customers (models/bad_customers.sql)
  Unrecognized name: num_orders at [9:61]
  compiled SQL at target/run/jaffle_shop/models/bad_customers.sql
Traceback (most recent call last):
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3083, in done
    self._query_results = self._client._get_query_results(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1288, in _get_query_results
    resource = self._call_api(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/dbt-demos/queries/e1d4da5d-ad46-49e1-8b39-b32a028b29a2?maxResults=0&location=US: Unrecognized name: num_orders at [9:61]

(job ID: e1d4da5d-ad46-49e1-8b39-b32a028b29a2)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.bad_customers"} */
   2:
   3:
   4:  create or replace table `dbt-demos`.`dbt_blake`.`bad_customers`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    select * from `dbt-demos`.`dbt_blake`.`customers` where num_orders = 0
  10:  );
  11:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/Users/blake/.virtualenvs/dbt-testing/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model bad_customers (models/bad_customers.sql)
  Unrecognized name: num_orders at [9:61]
  compiled SQL at target/run/jaffle_shop/models/bad_customers.sql
2020-12-11 22:48:30.915760 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c9f309d-9105-479a-8c22-2d7013f50900', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e25c070>]}
2020-12-11 22:48:30.917223 (Thread-1): 16:48:30 | 4 of 4 ERROR creating table model dbt_blake.bad_customers............ [ERROR in 2.21s]
2020-12-11 22:48:30.917396 (Thread-1): Finished running node model.jaffle_shop.bad_customers
2020-12-11 22:48:30.918684 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:48:30.919096 (MainThread): 16:48:30 | 
2020-12-11 22:48:30.919247 (MainThread): 16:48:30 | Finished running 3 table models, 1 view model in 8.62s.
2020-12-11 22:48:30.919358 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:48:30.919517 (MainThread): Connection 'model.jaffle_shop.bad_customers' was properly closed.
2020-12-11 22:48:30.933005 (MainThread): 
2020-12-11 22:48:30.933170 (MainThread): Completed with 1 error and 0 warnings:
2020-12-11 22:48:30.933257 (MainThread): 
2020-12-11 22:48:30.933336 (MainThread): Database Error in model bad_customers (models/bad_customers.sql)
2020-12-11 22:48:30.933408 (MainThread):   Unrecognized name: num_orders at [9:61]
2020-12-11 22:48:30.933471 (MainThread):   compiled SQL at target/run/jaffle_shop/models/bad_customers.sql
2020-12-11 22:48:30.933545 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2020-12-11 22:48:30.933757 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d14fdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d13d3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d15ef10>]}
2020-12-11 22:48:30.933939 (MainThread): Flushing usage events
2020-12-11 22:49:16.225568 (MainThread): Running with dbt=0.18.1
2020-12-11 22:49:16.420583 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:49:16.421674 (MainThread): Tracking: tracking
2020-12-11 22:49:16.430362 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b8b730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b9b7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b9b760>]}
2020-12-11 22:49:16.455613 (MainThread): Partial parsing not enabled
2020-12-11 22:49:16.457471 (MainThread): Parsing macros/etc.sql
2020-12-11 22:49:16.460993 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:49:16.467340 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:49:16.487485 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:49:16.490814 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:49:16.494085 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:49:16.503794 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:49:16.508206 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:49:16.522511 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:49:16.526272 (MainThread): Parsing macros/core.sql
2020-12-11 22:49:16.529935 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:49:16.538229 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:49:16.540039 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:49:16.558390 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:49:16.587359 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:49:16.607943 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:49:16.610356 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:49:16.617456 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:49:16.632435 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:49:16.639070 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:49:16.645492 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:49:16.650687 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:49:16.651836 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:49:16.653316 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:49:16.655063 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:49:16.664965 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:49:16.666974 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:49:16.668791 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:49:16.710450 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:49:16.712595 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:49:16.714307 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:49:16.716357 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:49:16.725504 (MainThread): Partial parsing not enabled
2020-12-11 22:49:16.794350 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:49:16.817199 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:49:16.829647 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:49:16.838419 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:49:16.977642 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:49:16.978849 (MainThread): 
2020-12-11 22:49:16.979208 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:49:16.983877 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:49:16.984031 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:49:17.261835 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:49:17.262354 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:49:17.263200 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:49:17.284785 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50754), raddr=('172.217.9.138', 443)>
2020-12-11 22:49:17.285312 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50755), raddr=('172.217.9.170', 443)>
2020-12-11 22:49:17.530953 (MainThread): 16:49:17 | Concurrency: 1 threads (target='dev')
2020-12-11 22:49:17.531370 (MainThread): 16:49:17 | 
2020-12-11 22:49:17.536962 (Thread-1): Began running node model.jaffle_shop.stg_customers
2020-12-11 22:49:17.538562 (Thread-1): 16:49:17 | 1 of 4 START table model dbt_blake.stg_customers..................... [RUN]
2020-12-11 22:49:17.539019 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:49:17.539188 (Thread-1): Compiling model.jaffle_shop.stg_customers
2020-12-11 22:49:17.559804 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:49:17.560440 (Thread-1): finished collecting timing info
2020-12-11 22:49:17.581430 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:49:17.581927 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:49:17.881696 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:49:17.882250 (Thread-1): On model.jaffle_shop.stg_customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_customers"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2020-12-11 22:49:19.858035 (Thread-1): finished collecting timing info
2020-12-11 22:49:19.858851 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '960c2366-c3fc-4476-bd16-a25644590f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105062580>]}
2020-12-11 22:49:19.860184 (Thread-1): 16:49:19 | 1 of 4 OK created table model dbt_blake.stg_customers................ [CREATE TABLE (100.0 rows, 1.9 KB processed) in 2.32s]
2020-12-11 22:49:19.860381 (Thread-1): Finished running node model.jaffle_shop.stg_customers
2020-12-11 22:49:19.860768 (Thread-1): Began running node model.jaffle_shop.stg_orders
2020-12-11 22:49:19.862814 (Thread-1): 16:49:19 | 2 of 4 START table model dbt_blake.stg_orders........................ [RUN]
2020-12-11 22:49:19.863345 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:49:19.863574 (Thread-1): Compiling model.jaffle_shop.stg_orders
2020-12-11 22:49:19.868873 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:49:19.869290 (Thread-1): finished collecting timing info
2020-12-11 22:49:19.872506 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:49:19.872947 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:49:20.141591 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:49:20.142479 (Thread-1): On model.jaffle_shop.stg_orders: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_orders"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2020-12-11 22:49:22.135982 (Thread-1): finished collecting timing info
2020-12-11 22:49:22.136948 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '960c2366-c3fc-4476-bd16-a25644590f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105081d30>]}
2020-12-11 22:49:22.138405 (Thread-1): 16:49:22 | 2 of 4 OK created table model dbt_blake.stg_orders................... [CREATE TABLE (99.0 rows, 3.3 KB processed) in 2.27s]
2020-12-11 22:49:22.138595 (Thread-1): Finished running node model.jaffle_shop.stg_orders
2020-12-11 22:49:22.139510 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:49:22.141451 (Thread-1): 16:49:22 | 3 of 4 START view model dbt_blake.customers.......................... [RUN]
2020-12-11 22:49:22.142171 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:49:22.142451 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:49:22.154025 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:49:22.154606 (Thread-1): finished collecting timing info
2020-12-11 22:49:22.166919 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50759), raddr=('172.217.9.170', 443)>
2020-12-11 22:49:22.167494 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50758), raddr=('172.217.9.138', 443)>
2020-12-11 22:49:22.167873 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50760), raddr=('172.217.9.138', 443)>
2020-12-11 22:49:22.168018 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50761), raddr=('172.217.9.170', 443)>
2020-12-11 22:49:22.178386 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.customers"
2020-12-11 22:49:22.179624 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:49:22.180150 (Thread-1): On model.jaffle_shop.customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.customers"} */


  create or replace view `dbt-demos`.`dbt_blake`.`customers`
  OPTIONS()
  as 


with customers as (

    select * from `dbt-demos`.`dbt_blake`.`stg_customers`
),

orders as (

    select * from `dbt-demos`.`dbt_blake`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2020-12-11 22:49:23.062391 (Thread-1): finished collecting timing info
2020-12-11 22:49:23.063673 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '960c2366-c3fc-4476-bd16-a25644590f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103da6a90>]}
2020-12-11 22:49:23.066531 (Thread-1): 16:49:23 | 3 of 4 OK created view model dbt_blake.customers..................... [CREATE VIEW in 0.92s]
2020-12-11 22:49:23.066853 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:49:23.067684 (Thread-1): Began running node model.jaffle_shop.bad_customers
2020-12-11 22:49:23.069144 (Thread-1): 16:49:23 | 4 of 4 START table model dbt_blake.bad_customers..................... [RUN]
2020-12-11 22:49:23.069552 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:49:23.069702 (Thread-1): Compiling model.jaffle_shop.bad_customers
2020-12-11 22:49:23.079394 (Thread-1): Writing injected SQL for node "model.jaffle_shop.bad_customers"
2020-12-11 22:49:23.079951 (Thread-1): finished collecting timing info
2020-12-11 22:49:23.085258 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.bad_customers"
2020-12-11 22:49:23.086000 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:49:23.086700 (Thread-1): On model.jaffle_shop.bad_customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.bad_customers"} */


  create or replace table `dbt-demos`.`dbt_blake`.`bad_customers`
  
  
  OPTIONS()
  as (
    select * from `dbt-demos`.`dbt_blake`.`customers` where number_of_orders = 0
  );
    
2020-12-11 22:49:25.719559 (Thread-1): finished collecting timing info
2020-12-11 22:49:25.720686 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '960c2366-c3fc-4476-bd16-a25644590f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10509e400>]}
2020-12-11 22:49:25.722384 (Thread-1): 16:49:25 | 4 of 4 OK created table model dbt_blake.bad_customers................ [CREATE TABLE (38.0 rows, 4.3 KB processed) in 2.65s]
2020-12-11 22:49:25.722614 (Thread-1): Finished running node model.jaffle_shop.bad_customers
2020-12-11 22:49:25.724618 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:49:25.725445 (MainThread): 16:49:25 | 
2020-12-11 22:49:25.725739 (MainThread): 16:49:25 | Finished running 3 table models, 1 view model in 8.75s.
2020-12-11 22:49:25.726033 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:49:25.726265 (MainThread): Connection 'model.jaffle_shop.bad_customers' was properly closed.
2020-12-11 22:49:25.743014 (MainThread): 
2020-12-11 22:49:25.743195 (MainThread): Completed successfully
2020-12-11 22:49:25.743309 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-12-11 22:49:25.743489 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb7340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb7220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb7280>]}
2020-12-11 22:49:25.743693 (MainThread): Flushing usage events
2020-12-11 22:50:13.327250 (MainThread): Running with dbt=0.18.1
2020-12-11 22:50:13.561606 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['stg_'], partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:50:13.563012 (MainThread): Tracking: tracking
2020-12-11 22:50:13.571095 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cb6fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cc36a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cc3640>]}
2020-12-11 22:50:13.596688 (MainThread): Partial parsing not enabled
2020-12-11 22:50:13.598043 (MainThread): Parsing macros/etc.sql
2020-12-11 22:50:13.601856 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:50:13.609020 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:50:13.629229 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:50:13.632179 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:50:13.635345 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:50:13.646168 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:50:13.651271 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:50:13.664969 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:50:13.668092 (MainThread): Parsing macros/core.sql
2020-12-11 22:50:13.672518 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:50:13.681575 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:50:13.683823 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:50:13.701314 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:50:13.730429 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:50:13.752341 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:50:13.755237 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:50:13.761717 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:50:13.776361 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:50:13.784234 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:50:13.791311 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:50:13.796969 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:50:13.798187 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:50:13.799442 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:50:13.801274 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:50:13.810831 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:50:13.813001 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:50:13.815227 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:50:13.858306 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:50:13.860610 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:50:13.862728 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:50:13.864606 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:50:13.873233 (MainThread): Partial parsing not enabled
2020-12-11 22:50:13.943247 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:50:13.966243 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:50:13.978586 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:50:13.988711 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:50:14.126718 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:50:14.127076 (MainThread): The selector 'stg_' does not match any nodes and will be ignored
2020-12-11 22:50:14.127453 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2020-12-11 22:50:14.127622 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f89a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f36d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f9ed90>]}
2020-12-11 22:50:14.127816 (MainThread): Flushing usage events
2020-12-11 22:50:14.437413 (MainThread): Connection 'model.jaffle_shop.stg_orders' was properly closed.
2020-12-11 22:51:06.835923 (MainThread): Running with dbt=0.18.1
2020-12-11 22:51:07.044379 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['staging.'], partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:51:07.045458 (MainThread): Tracking: tracking
2020-12-11 22:51:07.053499 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104369fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043766d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104376670>]}
2020-12-11 22:51:07.077501 (MainThread): Partial parsing not enabled
2020-12-11 22:51:07.079341 (MainThread): Parsing macros/etc.sql
2020-12-11 22:51:07.082203 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:51:07.088442 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:51:07.107748 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:51:07.110648 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:51:07.113542 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:51:07.123147 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:51:07.128208 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:51:07.140934 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:51:07.146747 (MainThread): Parsing macros/core.sql
2020-12-11 22:51:07.150854 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:51:07.159549 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:51:07.161254 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:51:07.177386 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:51:07.205714 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:51:07.225420 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:51:07.227348 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:51:07.233449 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:51:07.247246 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:51:07.253845 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:51:07.260009 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:51:07.264794 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:51:07.265774 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:51:07.266895 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:51:07.268546 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:51:07.277141 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:51:07.279096 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:51:07.280861 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:51:07.321111 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:51:07.323051 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:51:07.324635 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:51:07.326332 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:51:07.334222 (MainThread): Partial parsing not enabled
2020-12-11 22:51:07.398432 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:51:07.419767 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:51:07.429892 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:51:07.438770 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:51:07.568078 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:51:07.568417 (MainThread): The selector 'staging.' does not match any nodes and will be ignored
2020-12-11 22:51:07.569046 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2020-12-11 22:51:07.569235 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10463ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104611bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104651ee0>]}
2020-12-11 22:51:07.569583 (MainThread): Flushing usage events
2020-12-11 22:51:07.783251 (MainThread): Connection 'model.jaffle_shop.stg_orders' was properly closed.
2020-12-11 22:52:59.562498 (MainThread): Running with dbt=0.18.1
2020-12-11 22:52:59.742547 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['staging'], partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-12-11 22:52:59.743650 (MainThread): Tracking: tracking
2020-12-11 22:52:59.750917 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104178b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104187700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1041876a0>]}
2020-12-11 22:52:59.773981 (MainThread): Partial parsing not enabled
2020-12-11 22:52:59.775125 (MainThread): Parsing macros/etc.sql
2020-12-11 22:52:59.778096 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:52:59.784493 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:52:59.802897 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:52:59.805691 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:52:59.808547 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:52:59.818687 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:52:59.824236 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:52:59.837119 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:52:59.840000 (MainThread): Parsing macros/core.sql
2020-12-11 22:52:59.843738 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:52:59.853274 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:52:59.855045 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:52:59.871244 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:52:59.898631 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:52:59.919027 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:52:59.921112 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:52:59.927195 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:52:59.940598 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:52:59.947872 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:52:59.954170 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:52:59.958970 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:52:59.960108 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:52:59.961313 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:52:59.962966 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:52:59.971686 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:52:59.973709 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:52:59.975601 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:53:00.016999 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:53:00.018895 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:53:00.020483 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:53:00.022159 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:53:00.029917 (MainThread): Partial parsing not enabled
2020-12-11 22:53:00.093048 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:53:00.115006 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:53:00.125303 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:53:00.133972 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:53:00.265002 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:53:00.265608 (MainThread): 
2020-12-11 22:53:00.265904 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:53:00.268342 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos".
2020-12-11 22:53:00.268487 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:53:00.655657 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:53:00.656045 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-12-11 22:53:00.656802 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:53:00.712069 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50805), raddr=('172.217.9.138', 443)>
2020-12-11 22:53:00.712480 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50806), raddr=('172.217.9.170', 443)>
2020-12-11 22:53:00.983499 (MainThread): 16:53:00 | Concurrency: 1 threads (target='dev')
2020-12-11 22:53:00.983839 (MainThread): 16:53:00 | 
2020-12-11 22:53:00.991212 (Thread-1): Began running node model.jaffle_shop.stg_customers
2020-12-11 22:53:00.993141 (Thread-1): 16:53:00 | 1 of 2 START table model dbt_blake.stg_customers..................... [RUN]
2020-12-11 22:53:00.993575 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:53:00.993747 (Thread-1): Compiling model.jaffle_shop.stg_customers
2020-12-11 22:53:01.013009 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:53:01.013494 (Thread-1): finished collecting timing info
2020-12-11 22:53:01.033365 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:53:01.033894 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:53:01.334389 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:53:01.334959 (Thread-1): On model.jaffle_shop.stg_customers: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_customers"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2020-12-11 22:53:03.591239 (Thread-1): finished collecting timing info
2020-12-11 22:53:03.592318 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aafbc5d3-e49a-4202-87d6-dab1527f6039', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045a6e20>]}
2020-12-11 22:53:03.594011 (Thread-1): 16:53:03 | 1 of 2 OK created table model dbt_blake.stg_customers................ [CREATE TABLE (100.0 rows, 1.9 KB processed) in 2.60s]
2020-12-11 22:53:03.594241 (Thread-1): Finished running node model.jaffle_shop.stg_customers
2020-12-11 22:53:03.594455 (Thread-1): Began running node model.jaffle_shop.stg_orders
2020-12-11 22:53:03.596351 (Thread-1): 16:53:03 | 2 of 2 START table model dbt_blake.stg_orders........................ [RUN]
2020-12-11 22:53:03.596916 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:53:03.597094 (Thread-1): Compiling model.jaffle_shop.stg_orders
2020-12-11 22:53:03.604807 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:53:03.605362 (Thread-1): finished collecting timing info
2020-12-11 22:53:03.610073 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:53:03.610666 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:53:03.879965 (Thread-1): Writing runtime SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:53:03.881061 (Thread-1): On model.jaffle_shop.stg_orders: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "model.jaffle_shop.stg_orders"} */


  create or replace table `dbt-demos`.`dbt_blake`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2020-12-11 22:53:05.837354 (Thread-1): finished collecting timing info
2020-12-11 22:53:05.838755 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aafbc5d3-e49a-4202-87d6-dab1527f6039', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045b8e80>]}
2020-12-11 22:53:05.840750 (Thread-1): 16:53:05 | 2 of 2 OK created table model dbt_blake.stg_orders................... [CREATE TABLE (99.0 rows, 3.3 KB processed) in 2.24s]
2020-12-11 22:53:05.841022 (Thread-1): Finished running node model.jaffle_shop.stg_orders
2020-12-11 22:53:05.843169 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:53:05.844025 (MainThread): 16:53:05 | 
2020-12-11 22:53:05.844346 (MainThread): 16:53:05 | Finished running 2 table models in 5.58s.
2020-12-11 22:53:05.844589 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:53:05.844748 (MainThread): Connection 'model.jaffle_shop.stg_orders' was properly closed.
2020-12-11 22:53:05.856153 (MainThread): 
2020-12-11 22:53:05.856366 (MainThread): Completed successfully
2020-12-11 22:53:05.856499 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-12-11 22:53:05.856728 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043929a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045b8c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045b8c40>]}
2020-12-11 22:53:05.856982 (MainThread): Flushing usage events
2020-12-11 22:54:33.500004 (MainThread): Running with dbt=0.18.1
2020-12-11 22:54:33.737393 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-12-11 22:54:33.738607 (MainThread): Tracking: tracking
2020-12-11 22:54:33.746871 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc5dfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc6b6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc6b670>]}
2020-12-11 22:54:33.773045 (MainThread): Partial parsing not enabled
2020-12-11 22:54:33.774372 (MainThread): Parsing macros/etc.sql
2020-12-11 22:54:33.778912 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:54:33.785504 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:54:33.806609 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:54:33.809531 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:54:33.812649 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:54:33.822914 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:54:33.827519 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:54:33.842135 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:54:33.845163 (MainThread): Parsing macros/core.sql
2020-12-11 22:54:33.849156 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:54:33.857841 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:54:33.859750 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:54:33.877133 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:54:33.905999 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:54:33.926892 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:54:33.929588 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:54:33.936235 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:54:33.949910 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:54:33.956740 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:54:33.963591 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:54:33.969430 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:54:33.970729 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:54:33.972013 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:54:33.973852 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:54:33.982512 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:54:33.984774 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:54:33.986901 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:54:34.028189 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:54:34.030591 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:54:34.033053 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:54:34.035221 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:54:34.043390 (MainThread): Partial parsing not enabled
2020-12-11 22:54:34.108967 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:54:34.131143 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:54:34.142809 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:54:34.152014 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:54:34.469216 (MainThread): Found 4 models, 9 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:54:34.470219 (MainThread): 
2020-12-11 22:54:34.470514 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:54:34.485755 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:54:34.485921 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-12-11 22:54:34.486674 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:54:34.768773 (MainThread): 16:54:34 | Concurrency: 1 threads (target='dev')
2020-12-11 22:54:34.769062 (MainThread): 16:54:34 | 
2020-12-11 22:54:34.775739 (Thread-1): Began running node test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2020-12-11 22:54:34.775996 (Thread-1): 16:54:34 | 1 of 9 START test accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned [RUN]
2020-12-11 22:54:34.776485 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned".
2020-12-11 22:54:34.776683 (Thread-1): Compiling test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2020-12-11 22:54:34.801872 (Thread-1): Writing injected SQL for node "test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned"
2020-12-11 22:54:34.802554 (Thread-1): finished collecting timing info
2020-12-11 22:54:34.802882 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:34.803285 (Thread-1): On test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned"} */

    
    




with all_values as (

    select distinct
        status as value_field

    from `dbt-demos`.`dbt_blake`.`stg_orders`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        'placed','shipped','completed','return_pending','returned'
    )
)

select count(*) as validation_errors
from validation_errors



2020-12-11 22:54:35.926362 (Thread-1): finished collecting timing info
2020-12-11 22:54:35.927615 (Thread-1): 16:54:35 | 1 of 9 PASS accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned [PASS in 1.15s]
2020-12-11 22:54:35.927947 (Thread-1): Finished running node test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2020-12-11 22:54:35.928348 (Thread-1): Began running node test.jaffle_shop.not_null_customers_customer_id
2020-12-11 22:54:35.928937 (Thread-1): 16:54:35 | 2 of 9 START test not_null_customers_customer_id..................... [RUN]
2020-12-11 22:54:35.930042 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.not_null_customers_customer_id".
2020-12-11 22:54:35.930383 (Thread-1): Compiling test.jaffle_shop.not_null_customers_customer_id
2020-12-11 22:54:35.948463 (Thread-1): Writing injected SQL for node "test.jaffle_shop.not_null_customers_customer_id"
2020-12-11 22:54:35.949314 (Thread-1): finished collecting timing info
2020-12-11 22:54:35.949785 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:35.950652 (Thread-1): On test.jaffle_shop.not_null_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.not_null_customers_customer_id"} */

    
    



select count(*) as validation_errors
from `dbt-demos`.`dbt_blake`.`customers`
where customer_id is null



2020-12-11 22:54:37.343055 (Thread-1): finished collecting timing info
2020-12-11 22:54:37.344113 (Thread-1): 16:54:37 | 2 of 9 PASS not_null_customers_customer_id........................... [PASS in 1.41s]
2020-12-11 22:54:37.344471 (Thread-1): Finished running node test.jaffle_shop.not_null_customers_customer_id
2020-12-11 22:54:37.344683 (Thread-1): Began running node test.jaffle_shop.not_null_stg_customers_customer_id
2020-12-11 22:54:37.345045 (Thread-1): 16:54:37 | 3 of 9 START test not_null_stg_customers_customer_id................. [RUN]
2020-12-11 22:54:37.345456 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.not_null_stg_customers_customer_id".
2020-12-11 22:54:37.345630 (Thread-1): Compiling test.jaffle_shop.not_null_stg_customers_customer_id
2020-12-11 22:54:37.348590 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50830), raddr=('172.217.9.138', 443)>
2020-12-11 22:54:37.348948 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50831), raddr=('172.217.9.170', 443)>
2020-12-11 22:54:37.357983 (Thread-1): Writing injected SQL for node "test.jaffle_shop.not_null_stg_customers_customer_id"
2020-12-11 22:54:37.358527 (Thread-1): finished collecting timing info
2020-12-11 22:54:37.358798 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:37.359245 (Thread-1): On test.jaffle_shop.not_null_stg_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.not_null_stg_customers_customer_id"} */

    
    



select count(*) as validation_errors
from `dbt-demos`.`dbt_blake`.`stg_customers`
where customer_id is null



2020-12-11 22:54:38.509609 (Thread-1): finished collecting timing info
2020-12-11 22:54:38.510846 (Thread-1): 16:54:38 | 3 of 9 PASS not_null_stg_customers_customer_id....................... [PASS in 1.17s]
2020-12-11 22:54:38.511149 (Thread-1): Finished running node test.jaffle_shop.not_null_stg_customers_customer_id
2020-12-11 22:54:38.511401 (Thread-1): Began running node test.jaffle_shop.not_null_stg_orders_customer_id
2020-12-11 22:54:38.511737 (Thread-1): 16:54:38 | 4 of 9 START test not_null_stg_orders_customer_id.................... [RUN]
2020-12-11 22:54:38.512674 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.not_null_stg_orders_customer_id".
2020-12-11 22:54:38.512910 (Thread-1): Compiling test.jaffle_shop.not_null_stg_orders_customer_id
2020-12-11 22:54:38.518492 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50832), raddr=('172.217.9.138', 443)>
2020-12-11 22:54:38.518780 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50833), raddr=('172.217.9.170', 443)>
2020-12-11 22:54:38.528545 (Thread-1): Writing injected SQL for node "test.jaffle_shop.not_null_stg_orders_customer_id"
2020-12-11 22:54:38.529124 (Thread-1): finished collecting timing info
2020-12-11 22:54:38.529560 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:38.530233 (Thread-1): On test.jaffle_shop.not_null_stg_orders_customer_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.not_null_stg_orders_customer_id"} */

    
    



select count(*) as validation_errors
from `dbt-demos`.`dbt_blake`.`stg_orders`
where customer_id is null



2020-12-11 22:54:39.634967 (Thread-1): finished collecting timing info
2020-12-11 22:54:39.636686 (Thread-1): 16:54:39 | 4 of 9 PASS not_null_stg_orders_customer_id.......................... [PASS in 1.12s]
2020-12-11 22:54:39.637078 (Thread-1): Finished running node test.jaffle_shop.not_null_stg_orders_customer_id
2020-12-11 22:54:39.637397 (Thread-1): Began running node test.jaffle_shop.not_null_stg_orders_order_id
2020-12-11 22:54:39.638242 (Thread-1): 16:54:39 | 5 of 9 START test not_null_stg_orders_order_id....................... [RUN]
2020-12-11 22:54:39.638991 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.not_null_stg_orders_order_id".
2020-12-11 22:54:39.639251 (Thread-1): Compiling test.jaffle_shop.not_null_stg_orders_order_id
2020-12-11 22:54:39.648546 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50826), raddr=('172.217.9.138', 443)>
2020-12-11 22:54:39.648981 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50827), raddr=('172.217.9.170', 443)>
2020-12-11 22:54:39.649326 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50829), raddr=('172.217.9.170', 443)>
2020-12-11 22:54:39.649662 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50828), raddr=('172.217.9.138', 443)>
2020-12-11 22:54:39.658739 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50834), raddr=('172.217.9.138', 443)>
2020-12-11 22:54:39.659286 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50835), raddr=('172.217.9.170', 443)>
2020-12-11 22:54:39.667319 (Thread-1): Writing injected SQL for node "test.jaffle_shop.not_null_stg_orders_order_id"
2020-12-11 22:54:39.668053 (Thread-1): finished collecting timing info
2020-12-11 22:54:39.668419 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:39.669001 (Thread-1): On test.jaffle_shop.not_null_stg_orders_order_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.not_null_stg_orders_order_id"} */

    
    



select count(*) as validation_errors
from `dbt-demos`.`dbt_blake`.`stg_orders`
where order_id is null



2020-12-11 22:54:40.833594 (Thread-1): finished collecting timing info
2020-12-11 22:54:40.835145 (Thread-1): 16:54:40 | 5 of 9 PASS not_null_stg_orders_order_id............................. [PASS in 1.20s]
2020-12-11 22:54:40.835522 (Thread-1): Finished running node test.jaffle_shop.not_null_stg_orders_order_id
2020-12-11 22:54:40.835838 (Thread-1): Began running node test.jaffle_shop.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2020-12-11 22:54:40.836170 (Thread-1): 16:54:40 | 6 of 9 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ [RUN]
2020-12-11 22:54:40.837497 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_".
2020-12-11 22:54:40.837807 (Thread-1): Compiling test.jaffle_shop.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2020-12-11 22:54:40.859527 (Thread-1): Writing injected SQL for node "test.jaffle_shop.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_"
2020-12-11 22:54:40.860177 (Thread-1): finished collecting timing info
2020-12-11 22:54:40.860574 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:40.861053 (Thread-1): On test.jaffle_shop.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_"} */

    
    




select count(*) as validation_errors
from (
    select customer_id as id from `dbt-demos`.`dbt_blake`.`stg_orders`
) as child
left join (
    select customer_id as id from `dbt-demos`.`dbt_blake`.`stg_customers`
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null



2020-12-11 22:54:41.940993 (Thread-1): finished collecting timing info
2020-12-11 22:54:41.942275 (Thread-1): 16:54:41 | 6 of 9 PASS relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ [PASS in 1.11s]
2020-12-11 22:54:41.942633 (Thread-1): Finished running node test.jaffle_shop.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2020-12-11 22:54:41.942927 (Thread-1): Began running node test.jaffle_shop.unique_customers_customer_id
2020-12-11 22:54:41.943887 (Thread-1): 16:54:41 | 7 of 9 START test unique_customers_customer_id....................... [RUN]
2020-12-11 22:54:41.945144 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.unique_customers_customer_id".
2020-12-11 22:54:41.945533 (Thread-1): Compiling test.jaffle_shop.unique_customers_customer_id
2020-12-11 22:54:41.950252 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50838), raddr=('172.217.9.138', 443)>
2020-12-11 22:54:41.950722 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50839), raddr=('172.217.9.170', 443)>
2020-12-11 22:54:41.964303 (Thread-1): Writing injected SQL for node "test.jaffle_shop.unique_customers_customer_id"
2020-12-11 22:54:41.965162 (Thread-1): finished collecting timing info
2020-12-11 22:54:41.965614 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:41.966186 (Thread-1): On test.jaffle_shop.unique_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.unique_customers_customer_id"} */

    
    



select count(*) as validation_errors
from (

    select
        customer_id

    from `dbt-demos`.`dbt_blake`.`customers`
    where customer_id is not null
    group by customer_id
    having count(*) > 1

) validation_errors



2020-12-11 22:54:43.406844 (Thread-1): finished collecting timing info
2020-12-11 22:54:43.408182 (Thread-1): 16:54:43 | 7 of 9 PASS unique_customers_customer_id............................. [PASS in 1.46s]
2020-12-11 22:54:43.408851 (Thread-1): Finished running node test.jaffle_shop.unique_customers_customer_id
2020-12-11 22:54:43.409479 (Thread-1): Began running node test.jaffle_shop.unique_stg_customers_customer_id
2020-12-11 22:54:43.409973 (Thread-1): 16:54:43 | 8 of 9 START test unique_stg_customers_customer_id................... [RUN]
2020-12-11 22:54:43.410839 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.unique_stg_customers_customer_id".
2020-12-11 22:54:43.411055 (Thread-1): Compiling test.jaffle_shop.unique_stg_customers_customer_id
2020-12-11 22:54:43.417502 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50842), raddr=('172.217.9.138', 443)>
2020-12-11 22:54:43.418153 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50843), raddr=('172.217.9.170', 443)>
2020-12-11 22:54:43.429355 (Thread-1): Writing injected SQL for node "test.jaffle_shop.unique_stg_customers_customer_id"
2020-12-11 22:54:43.429986 (Thread-1): finished collecting timing info
2020-12-11 22:54:43.430526 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:43.431161 (Thread-1): On test.jaffle_shop.unique_stg_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.unique_stg_customers_customer_id"} */

    
    



select count(*) as validation_errors
from (

    select
        customer_id

    from `dbt-demos`.`dbt_blake`.`stg_customers`
    where customer_id is not null
    group by customer_id
    having count(*) > 1

) validation_errors



2020-12-11 22:54:44.795659 (Thread-1): finished collecting timing info
2020-12-11 22:54:44.797041 (Thread-1): 16:54:44 | 8 of 9 PASS unique_stg_customers_customer_id......................... [PASS in 1.39s]
2020-12-11 22:54:44.797381 (Thread-1): Finished running node test.jaffle_shop.unique_stg_customers_customer_id
2020-12-11 22:54:44.797683 (Thread-1): Began running node test.jaffle_shop.unique_stg_orders_order_id
2020-12-11 22:54:44.798146 (Thread-1): 16:54:44 | 9 of 9 START test unique_stg_orders_order_id......................... [RUN]
2020-12-11 22:54:44.799670 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.unique_stg_orders_order_id".
2020-12-11 22:54:44.800120 (Thread-1): Compiling test.jaffle_shop.unique_stg_orders_order_id
2020-12-11 22:54:44.818350 (Thread-1): Writing injected SQL for node "test.jaffle_shop.unique_stg_orders_order_id"
2020-12-11 22:54:44.819191 (Thread-1): finished collecting timing info
2020-12-11 22:54:44.819746 (Thread-1): Opening a new connection, currently in state closed
2020-12-11 22:54:44.820543 (Thread-1): On test.jaffle_shop.unique_stg_orders_order_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "node_id": "test.jaffle_shop.unique_stg_orders_order_id"} */

    
    



select count(*) as validation_errors
from (

    select
        order_id

    from `dbt-demos`.`dbt_blake`.`stg_orders`
    where order_id is not null
    group by order_id
    having count(*) > 1

) validation_errors



2020-12-11 22:54:46.059524 (Thread-1): finished collecting timing info
2020-12-11 22:54:46.061073 (Thread-1): 16:54:46 | 9 of 9 PASS unique_stg_orders_order_id............................... [PASS in 1.26s]
2020-12-11 22:54:46.061405 (Thread-1): Finished running node test.jaffle_shop.unique_stg_orders_order_id
2020-12-11 22:54:46.063963 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:54:46.064861 (MainThread): 16:54:46 | 
2020-12-11 22:54:46.065206 (MainThread): 16:54:46 | Finished running 9 tests in 11.59s.
2020-12-11 22:54:46.065574 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:54:46.065938 (MainThread): Connection 'test.jaffle_shop.unique_stg_orders_order_id' was properly closed.
2020-12-11 22:54:46.089932 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50847), raddr=('172.217.9.138', 443)>
2020-12-11 22:54:46.090226 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.232', 50848), raddr=('172.217.9.170', 443)>
2020-12-11 22:54:46.103632 (MainThread): 
2020-12-11 22:54:46.103791 (MainThread): Completed successfully
2020-12-11 22:54:46.103896 (MainThread): 
Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
2020-12-11 22:54:46.104053 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be42ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf40490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf40160>]}
2020-12-11 22:54:46.104219 (MainThread): Flushing usage events
2020-12-11 22:59:39.783658 (MainThread): Running with dbt=0.18.1
2020-12-11 22:59:39.976003 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-12-11 22:59:39.976897 (MainThread): Tracking: tracking
2020-12-11 22:59:39.984759 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059fdb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a0c700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a0c6a0>]}
2020-12-11 22:59:40.008634 (MainThread): Partial parsing not enabled
2020-12-11 22:59:40.009717 (MainThread): Parsing macros/etc.sql
2020-12-11 22:59:40.012483 (MainThread): Parsing macros/catalog.sql
2020-12-11 22:59:40.018786 (MainThread): Parsing macros/adapters.sql
2020-12-11 22:59:40.040497 (MainThread): Parsing macros/materializations/seed.sql
2020-12-11 22:59:40.043323 (MainThread): Parsing macros/materializations/view.sql
2020-12-11 22:59:40.047063 (MainThread): Parsing macros/materializations/table.sql
2020-12-11 22:59:40.059639 (MainThread): Parsing macros/materializations/copy.sql
2020-12-11 22:59:40.064782 (MainThread): Parsing macros/materializations/incremental.sql
2020-12-11 22:59:40.078580 (MainThread): Parsing macros/materializations/snapshot.sql
2020-12-11 22:59:40.081478 (MainThread): Parsing macros/core.sql
2020-12-11 22:59:40.085016 (MainThread): Parsing macros/materializations/helpers.sql
2020-12-11 22:59:40.094106 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-12-11 22:59:40.095914 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-12-11 22:59:40.112629 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-12-11 22:59:40.140931 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-12-11 22:59:40.161589 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-12-11 22:59:40.163492 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-12-11 22:59:40.169795 (MainThread): Parsing macros/materializations/common/merge.sql
2020-12-11 22:59:40.183297 (MainThread): Parsing macros/materializations/table/table.sql
2020-12-11 22:59:40.190367 (MainThread): Parsing macros/materializations/view/view.sql
2020-12-11 22:59:40.196995 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-12-11 22:59:40.202418 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-12-11 22:59:40.203514 (MainThread): Parsing macros/etc/query.sql
2020-12-11 22:59:40.204638 (MainThread): Parsing macros/etc/is_incremental.sql
2020-12-11 22:59:40.206375 (MainThread): Parsing macros/etc/datetime.sql
2020-12-11 22:59:40.214969 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-12-11 22:59:40.216877 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-12-11 22:59:40.218582 (MainThread): Parsing macros/adapters/common.sql
2020-12-11 22:59:40.260544 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-12-11 22:59:40.262528 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-12-11 22:59:40.264079 (MainThread): Parsing macros/schema_tests/unique.sql
2020-12-11 22:59:40.265800 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-12-11 22:59:40.274434 (MainThread): Partial parsing not enabled
2020-12-11 22:59:40.340237 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:59:40.362544 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:59:40.373724 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:59:40.382370 (MainThread): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:59:40.666653 (MainThread): Found 4 models, 7 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-12-11 22:59:40.668842 (MainThread): 
2020-12-11 22:59:40.669374 (MainThread): Acquiring new bigquery connection "master".
2020-12-11 22:59:40.681087 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-demos_dbt_blake".
2020-12-11 22:59:40.681245 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-12-11 22:59:40.681881 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-12-11 22:59:41.061162 (MainThread): 16:59:41 | Concurrency: 1 threads (target='dev')
2020-12-11 22:59:41.061530 (MainThread): 16:59:41 | 
2020-12-11 22:59:41.067843 (Thread-1): Began running node model.jaffle_shop.stg_customers
2020-12-11 22:59:41.068525 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_customers".
2020-12-11 22:59:41.068777 (Thread-1): Compiling model.jaffle_shop.stg_customers
2020-12-11 22:59:41.091211 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_customers"
2020-12-11 22:59:41.091701 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.091978 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.092328 (Thread-1): Finished running node model.jaffle_shop.stg_customers
2020-12-11 22:59:41.092442 (Thread-1): Began running node model.jaffle_shop.stg_orders
2020-12-11 22:59:41.092851 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.stg_orders".
2020-12-11 22:59:41.092992 (Thread-1): Compiling model.jaffle_shop.stg_orders
2020-12-11 22:59:41.098740 (Thread-1): Writing injected SQL for node "model.jaffle_shop.stg_orders"
2020-12-11 22:59:41.099566 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.099839 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.100202 (Thread-1): Finished running node model.jaffle_shop.stg_orders
2020-12-11 22:59:41.100315 (Thread-1): Began running node test.jaffle_shop.not_null_stg_customers_customer_id
2020-12-11 22:59:41.100529 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.not_null_stg_customers_customer_id".
2020-12-11 22:59:41.100895 (Thread-1): Compiling test.jaffle_shop.not_null_stg_customers_customer_id
2020-12-11 22:59:41.115763 (Thread-1): Writing injected SQL for node "test.jaffle_shop.not_null_stg_customers_customer_id"
2020-12-11 22:59:41.116217 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.116543 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.116886 (Thread-1): Finished running node test.jaffle_shop.not_null_stg_customers_customer_id
2020-12-11 22:59:41.116997 (Thread-1): Began running node test.jaffle_shop.unique_stg_customers_customer_id
2020-12-11 22:59:41.117292 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.unique_stg_customers_customer_id".
2020-12-11 22:59:41.117399 (Thread-1): Compiling test.jaffle_shop.unique_stg_customers_customer_id
2020-12-11 22:59:41.125846 (Thread-1): Writing injected SQL for node "test.jaffle_shop.unique_stg_customers_customer_id"
2020-12-11 22:59:41.126366 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.126634 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.126969 (Thread-1): Finished running node test.jaffle_shop.unique_stg_customers_customer_id
2020-12-11 22:59:41.127079 (Thread-1): Began running node model.jaffle_shop.customers
2020-12-11 22:59:41.127273 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.customers".
2020-12-11 22:59:41.127358 (Thread-1): Compiling model.jaffle_shop.customers
2020-12-11 22:59:41.136508 (Thread-1): Writing injected SQL for node "model.jaffle_shop.customers"
2020-12-11 22:59:41.137596 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.137870 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.138325 (Thread-1): Finished running node model.jaffle_shop.customers
2020-12-11 22:59:41.138458 (Thread-1): Began running node test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2020-12-11 22:59:41.138673 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned".
2020-12-11 22:59:41.138761 (Thread-1): Compiling test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2020-12-11 22:59:41.148463 (Thread-1): Writing injected SQL for node "test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned"
2020-12-11 22:59:41.149468 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.149710 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.150040 (Thread-1): Finished running node test.jaffle_shop.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2020-12-11 22:59:41.150149 (Thread-1): Began running node test.jaffle_shop.not_null_stg_orders_order_id
2020-12-11 22:59:41.150347 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.not_null_stg_orders_order_id".
2020-12-11 22:59:41.150431 (Thread-1): Compiling test.jaffle_shop.not_null_stg_orders_order_id
2020-12-11 22:59:41.159054 (Thread-1): Writing injected SQL for node "test.jaffle_shop.not_null_stg_orders_order_id"
2020-12-11 22:59:41.159587 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.159824 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.160172 (Thread-1): Finished running node test.jaffle_shop.not_null_stg_orders_order_id
2020-12-11 22:59:41.160288 (Thread-1): Began running node test.jaffle_shop.unique_stg_orders_order_id
2020-12-11 22:59:41.160558 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.unique_stg_orders_order_id".
2020-12-11 22:59:41.160646 (Thread-1): Compiling test.jaffle_shop.unique_stg_orders_order_id
2020-12-11 22:59:41.168363 (Thread-1): Writing injected SQL for node "test.jaffle_shop.unique_stg_orders_order_id"
2020-12-11 22:59:41.168872 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.169128 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.169557 (Thread-1): Finished running node test.jaffle_shop.unique_stg_orders_order_id
2020-12-11 22:59:41.169837 (Thread-1): Began running node model.jaffle_shop.bad_customers
2020-12-11 22:59:41.170311 (Thread-1): Acquiring new bigquery connection "model.jaffle_shop.bad_customers".
2020-12-11 22:59:41.170428 (Thread-1): Compiling model.jaffle_shop.bad_customers
2020-12-11 22:59:41.176770 (Thread-1): Writing injected SQL for node "model.jaffle_shop.bad_customers"
2020-12-11 22:59:41.177231 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.177456 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.177779 (Thread-1): Finished running node model.jaffle_shop.bad_customers
2020-12-11 22:59:41.177886 (Thread-1): Began running node test.jaffle_shop.not_null_customers_customer_id
2020-12-11 22:59:41.178170 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.not_null_customers_customer_id".
2020-12-11 22:59:41.178273 (Thread-1): Compiling test.jaffle_shop.not_null_customers_customer_id
2020-12-11 22:59:41.186240 (Thread-1): Writing injected SQL for node "test.jaffle_shop.not_null_customers_customer_id"
2020-12-11 22:59:41.186634 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.186893 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.187403 (Thread-1): Finished running node test.jaffle_shop.not_null_customers_customer_id
2020-12-11 22:59:41.187831 (Thread-1): Began running node test.jaffle_shop.unique_customers_customer_id
2020-12-11 22:59:41.188127 (Thread-1): Acquiring new bigquery connection "test.jaffle_shop.unique_customers_customer_id".
2020-12-11 22:59:41.188243 (Thread-1): Compiling test.jaffle_shop.unique_customers_customer_id
2020-12-11 22:59:41.197703 (Thread-1): Writing injected SQL for node "test.jaffle_shop.unique_customers_customer_id"
2020-12-11 22:59:41.198202 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.198524 (Thread-1): finished collecting timing info
2020-12-11 22:59:41.198960 (Thread-1): Finished running node test.jaffle_shop.unique_customers_customer_id
2020-12-11 22:59:41.199794 (MainThread): Connection 'master' was properly closed.
2020-12-11 22:59:41.199984 (MainThread): Connection 'test.jaffle_shop.unique_customers_customer_id' was properly closed.
2020-12-11 22:59:41.228129 (MainThread): 16:59:41 | Done.
2020-12-11 22:59:41.231463 (MainThread): Acquiring new bigquery connection "generate_catalog".
2020-12-11 22:59:41.231722 (MainThread): 16:59:41 | Building catalog
2020-12-11 22:59:41.249327 (MainThread): Opening a new connection, currently in state init
2020-12-11 22:59:41.530098 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "dbt-demos.information_schema".
2020-12-11 22:59:41.557680 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-12-11 22:59:41.558542 (ThreadPoolExecutor-1_0): On dbt-demos.information_schema: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "jaffle_shop", "target_name": "dev", "connection_name": "dbt-demos.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `dbt-demos`.`dbt_blake`.__TABLES__
        where (upper(dataset_id) = upper('dbt_blake'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `dbt-demos`.`dbt_blake`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `dbt-demos`.`dbt_blake`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2020-12-11 22:59:44.262693 (MainThread): 16:59:44 | Catalog written to /Users/blake/Documents/dbt-tutorial/jaffle-shop/target/catalog.json
2020-12-11 22:59:44.262951 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059fdb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e8e850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e8e6a0>]}
2020-12-11 22:59:44.263145 (MainThread): Flushing usage events
2020-12-11 22:59:44.550314 (MainThread): Connection 'generate_catalog' was properly closed.
2020-12-11 22:59:44.550660 (MainThread): Connection 'dbt-demos.information_schema' was properly closed.
2020-12-11 23:00:04.440285 (MainThread): Running with dbt=0.18.1
2020-12-11 23:00:04.643663 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', open_browser=True, partial_parse=None, port=8080, profile=None, profiles_dir='/Users/blake/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='serve', write_json=True)
2020-12-11 23:00:04.644702 (MainThread): Tracking: tracking
2020-12-11 23:00:04.653828 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058dbf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e9670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e9610>]}
2020-12-11 23:00:04.656662 (MainThread): Serving docs at 0.0.0.0:8080
2020-12-11 23:00:04.656845 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2020-12-11 23:00:04.656929 (MainThread): Press Ctrl+C to exit.


2020-12-11 23:01:44.454068 (MainThread): Flushing usage events
2020-12-11 23:01:44.797658 (MainThread): ctrl-c
